{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN7pBjLAdEdArpgDdyjUXbw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### MMDetection 설치\n","* 강의 영상에는 pip install mmcv-full로 mmcv를 설치(약 10분 정도의 시간이 소요)\n","* 실습코드는 pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13/index.html 로 변경(설치에 12초 정도 걸림. 2022.09).\n","* 코랩의 pytorch 버전이 2.0으로 upgrade되었으나 mmdetection은 아직 pytorch 2.0을 지원하지 않기에 pytorch 1.13으로 downgrade 필요(2023.04월에 코랩 pytorch upgrade)\n","*  2023년 4월 6일 기준으로 mmdetection이 3.0으로 upgrade됨. 실습 코드는 mmdetection 2.x 기준으므로 mmdetection 2.x 소스코드 설치 필요."],"metadata":{"id":"oU_f8xJqYND1"}},{"cell_type":"code","source":["#코랩의 pytorch 버전이 2.0으로 upgrade됨. \n","import torch\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Kaz5nrDYPId","executionInfo":{"status":"ok","timestamp":1680848645215,"user_tz":-540,"elapsed":5969,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"42db17c6-7294-4699-92a3-050d902f6e11"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.0+cu118\n"]}]},{"cell_type":"code","source":["#현재 mmdetection이 pytorch 2.x를 지원하지 않음. pytorch 1.13+ CUDA 116 환경으로 코랩 커널 downgrade\n","# downgrade 설치시 ERROR: pip's dependency resolver... 부분은 신경쓰지 않아도 됨. \n","!pip install torch==1.13.0+cu116 torchvision==0.14.0+cu116 --extra-index-url https://download.pytorch.org/whl/cu116"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vdTHnass8wQC","executionInfo":{"status":"ok","timestamp":1680848844296,"user_tz":-540,"elapsed":119623,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"ae87bb5f-f633-4f18-d1ab-24d172fe402a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n","Collecting torch==1.13.0+cu116\n","  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.0%2Bcu116-cp39-cp39-linux_x86_64.whl (1983.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m870.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.14.0+cu116\n","  Downloading https://download.pytorch.org/whl/cu116/torchvision-0.14.0%2Bcu116-cp39-cp39-linux_x86_64.whl (24.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.0+cu116) (4.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.0+cu116) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.0+cu116) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.0+cu116) (1.22.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.0+cu116) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.0+cu116) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.0+cu116) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.0+cu116) (2022.12.7)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.0+cu118\n","    Uninstalling torch-2.0.0+cu118:\n","      Successfully uninstalled torch-2.0.0+cu118\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.15.1+cu118\n","    Uninstalling torchvision-0.15.1+cu118:\n","      Successfully uninstalled torchvision-0.15.1+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.0+cu116 which is incompatible.\n","torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.0+cu116 which is incompatible.\n","torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.0+cu116 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.13.0+cu116 torchvision-0.14.0+cu116\n"]}]},{"cell_type":"code","metadata":{"id":"pEP0cZDIM532","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680848915509,"user_tz":-540,"elapsed":10920,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"2c5c9171-159b-49dc-94ab-a6abc3efc74f"},"source":["# mmcv를 위해서 mmcv-full을 먼저 설치해야 함. https://mmcv.readthedocs.io/en/latest/get_started/installation.html 설치 과정 참조.\n","!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13/index.html"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu116/torch1.13/index.html\n","Collecting mmcv-full\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/mmcv_full-1.7.1-cp39-cp39-manylinux1_x86_64.whl (46.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mmcv-full) (23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mmcv-full) (1.22.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from mmcv-full) (6.0)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from mmcv-full) (8.4.0)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.9/dist-packages (from mmcv-full) (4.7.0.72)\n","Installing collected packages: yapf, addict, mmcv-full\n","Successfully installed addict-2.4.0 mmcv-full-1.7.1 yapf-0.32.0\n"]}]},{"cell_type":"code","source":["# 2023년 4월 6일 기준으로 mmdetection이 3.0으로 upgrade됨. 실습 코드는 mmdetection 2.x 기준임. \n","# mmdetection 2.x branch의 소스코드 기반으로 mmdetection 설치 필요. \n","!git clone --branch 2.x https://github.com/open-mmlab/mmdetection.git\n","!cd mmdetection; python setup.py install"],"metadata":{"id":"6AbNjP5eFBGu"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kNPWIavsNLiU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680848995001,"user_tz":-540,"elapsed":5207,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"08a3d997-e67f-4ce4-d5e0-98a65592b474"},"source":["# 아래를 수행하기 전에 kernel을 restart 해야 함. \n","from mmdet.apis import init_detector, inference_detector\n","import mmcv"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n"]}]},{"cell_type":"code","metadata":{"id":"u7ioe-yYNTke"},"source":["!cat /proc/meminfo"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6P6NuYF-NfA_"},"source":["### KITTI Dataset 다운로드\n","* 작은 용량의 KITTI Dataset을 다운로드하고 /content 밑에 압축 해제"]},{"cell_type":"code","metadata":{"id":"To699_wUNTqd"},"source":["!wget https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\n","!unzip kitti_tiny.zip > /dev/null"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WzvmxaXQNTum"},"source":["import matplotlib.pyplot as plt\n","import cv2\n","\n","img = cv2.cvtColor(cv2.imread('/content/kitti_tiny/training/image_2/000068.jpeg'), cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(15, 10))\n","plt.imshow(img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oazYURVlPFj_"},"source":["### KITTI DATA FORMAT 확인\n","* 첫번째 컬럼은 해당 오브젝트의 클래스 명. \n","* 5번째~8번째가 BOUNDING BOX 정보임. 좌상단(xmin, ymin), 우하단(xmax, ymax) 좌표 임. "]},{"cell_type":"code","metadata":{"id":"2SvhCg0pNTxx"},"source":["!cat /content/kitti_tiny/training/label_2/000068.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ER_5_wDaPtfG"},"source":["### KITTI annotation 파일들의 리스트들을 가지는 파일 확인. "]},{"cell_type":"code","metadata":{"id":"r89SNcIqP0H2"},"source":["!cat /content/kitti_tiny/train.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7xUFbisuO1S5"},"source":["### mmdetection의 중립 annotation 포맷 변환. 해당 포맷은 텍스트로 변환하지 않음. 바로 메모리 상의 list로 생성됨.  \n","#### filename, width, height, ann을 Key로 가지는 Dictionary를 이미지 개수대로 가지는 list 생성. \n","* filename: 이미지 파일명(디렉토리는 포함하지 않음)\n","* width: 이미지 너비\n","* height: 이미지 높이\n","* ann: bbounding box와 label에 대한 정보를 가지는 Dictionary\n"," - bboxes: 하나의 이미지에 있는 여러 Object 들의 numpy array. 4개의 좌표값(좌상단, 우하단)을 가지고, 해당 이미지에 n개의 Object들이 있을 경우 array의 shape는 (n, 4)\n"," - labels: 하나의 이미지에 있는 여러 Object들의 numpy array. shape는 (n, )\n"," - bboxes_ignore: 학습에 사용되지 않고 무시하는 bboxes. 무시하는 bboxes의 개수가 k개이면 shape는 (k, 4)\n"," - labels_ignore: 학습에 사용되지 않고 무시하는 labels. 무시하는 bboxes의 개수가 k개이면 shape는 (k,)\n","\n","\n","\n","![mmdetection_anno.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"ZBdOvUOfVN8U"},"source":["### kitti Dataset을 중립 데이터형태로 변환하여 메모리 로드"]},{"cell_type":"code","metadata":{"id":"YAUEpbYSUfOO"},"source":["# 원본 kitti Dataset는 10개의 Class로 되어 있음. 'Car Van Truck Pedestrian Person_sitting Cyclist Tram Misc DontCare'\n","CLASSES = ('Car', 'Truck', 'Pedestrian', 'Cyclist')\n","cat2label = {k:i for i, k in enumerate(CLASSES)}\n","print(cat2label)\n","cat2label['Car']\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KaX7JmJoDTq"},"source":["image_list = mmcv.list_from_file('/content/kitti_tiny/train.txt')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GyRjJQBl48cM"},"source":["lines = mmcv.list_from_file('/content/kitti_tiny/training/label_2/000064.txt')\n","#print(lines)\n","content = [line.strip().split(' ') for line in lines]\n","bbox_names = [x[0] for x in content]\n","#print(bbox_names)\n","bboxes = [ [float(info) for info in x[4:8]] for x in content]\n","print(bboxes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9LF0FKWO3rF"},"source":["import copy\n","import os.path as osp\n","import cv2\n","\n","import mmcv\n","import numpy as np\n","\n","from mmdet.datasets.builder import DATASETS\n","from mmdet.datasets.custom import CustomDataset\n","\n","# 반드시 아래 Decorator 설정 할것.@DATASETS.register_module() 설정 시 force=True를 입력하지 않으면 Dataset 재등록 불가. \n","@DATASETS.register_module(force=True)\n","class KittyTinyDataset(CustomDataset):\n","  CLASSES = ('Car', 'Truck', 'Pedestrian', 'Cyclist')\n","  \n","  ##### self.data_root: /content/kitti_tiny/ self.ann_file: /content/kitti_tiny/train.txt self.img_prefix: /content/kitti_tiny/training/image_2\n","  #### ann_file: /content/kitti_tiny/train.txt\n","  # annotation에 대한 모든 파일명을 가지고 있는 텍스트 파일을 __init__(self, ann_file)로 입력 받고, 이 self.ann_file이 load_annotations()의 인자로 입력\n","  def load_annotations(self, ann_file):\n","    print('##### self.data_root:', self.data_root, 'self.ann_file:', self.ann_file, 'self.img_prefix:', self.img_prefix)\n","    print('#### ann_file:', ann_file)\n","    cat2label = {k:i for i, k in enumerate(self.CLASSES)}\n","    image_list = mmcv.list_from_file(self.ann_file)\n","    # 포맷 중립 데이터를 담을 list 객체\n","    data_infos = []\n","    \n","    for image_id in image_list:\n","      filename = '{0:}/{1:}.jpeg'.format(self.img_prefix, image_id)\n","      # 원본 이미지의 너비, 높이를 image를 직접 로드하여 구함. \n","      image = cv2.imread(filename)\n","      height, width = image.shape[:2]\n","      # 개별 image의 annotation 정보 저장용 Dict 생성. key값 filename 에는 image의 파일명만 들어감(디렉토리는 제외)\n","      data_info = {'filename': str(image_id) + '.jpeg',\n","                   'width': width, 'height': height}\n","      # 개별 annotation이 있는 서브 디렉토리의 prefix 변환. \n","      label_prefix = self.img_prefix.replace('image_2', 'label_2')\n","      # 개별 annotation 파일을 1개 line 씩 읽어서 list 로드 \n","      lines = mmcv.list_from_file(osp.join(label_prefix, str(image_id)+'.txt'))\n","\n","      # 전체 lines를 개별 line별 공백 레벨로 parsing 하여 다시 list로 저장. content는 list의 list형태임.\n","      # ann 정보는 numpy array로 저장되나 텍스트 처리나 데이터 가공이 list 가 편하므로 일차적으로 list로 변환 수행.   \n","      content = [line.strip().split(' ') for line in lines]\n","      # 오브젝트의 클래스명은 bbox_names로 저장. \n","      bbox_names = [x[0] for x in content]\n","      # bbox 좌표를 저장\n","      bboxes = [ [float(info) for info in x[4:8]] for x in content]\n","\n","      # 클래스명이 해당 사항이 없는 대상 Filtering out, 'DontCare'sms ignore로 별도 저장.\n","      gt_bboxes = []\n","      gt_labels = []\n","      gt_bboxes_ignore = []\n","      gt_labels_ignore = []\n","\n","      for bbox_name, bbox in zip(bbox_names, bboxes):\n","        # 만약 bbox_name이 클래스명에 해당 되면, gt_bboxes와 gt_labels에 추가, 그렇지 않으면 gt_bboxes_ignore, gt_labels_ignore에 추가\n","        if bbox_name in cat2label:\n","          gt_bboxes.append(bbox)\n","          # gt_labels에는 class id를 입력\n","          gt_labels.append(cat2label[bbox_name])\n","        \n","        else:\n","          gt_bboxes_ignore.append(bbox)\n","          gt_labels_ignore.append(-1)\n","      # 개별 image별 annotation 정보를 가지는 Dict 생성. 해당 Dict의 value값은 모두 np.array임. \n","      data_anno = {\n","          'bboxes': np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n","          'labels': np.array(gt_labels, dtype=np.long),\n","          'bboxes_ignore': np.array(gt_bboxes_ignore, dtype=np.float32).reshape(-1, 4),\n","          'labels_ignore': np.array(gt_labels_ignore, dtype=np.long)\n","      }\n","      # image에 대한 메타 정보를 가지는 data_info Dict에 'ann' key값으로 data_anno를 value로 저장. \n","      data_info.update(ann=data_anno)\n","      # 전체 annotation 파일들에 대한 정보를 가지는 data_infos에 data_info Dict를 추가\n","      data_infos.append(data_info)\n","\n","    return data_infos\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OAm8tH0GKWwf"},"source":["### Config 설정하고 Pretrained 모델 다운로드\n","config_file = '/content/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n","checkpoint_file = '/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8XUFGc6K-ON"},"source":["!cd mmdetection; mkdir checkpoints\n","!wget -O /content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mc-TPyQkfIwk"},"source":["from mmcv import Config\n","\n","cfg = Config.fromfile(config_file)\n","print(cfg.pretty_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l6DnkHuvl5WY"},"source":["from mmdet.apis import set_random_seed\n","\n","# dataset에 대한 환경 파라미터 수정. \n","cfg.dataset_type = 'KittyTinyDataset'\n","cfg.data_root = '/content/kitti_tiny/'\n","\n","# train, val, test dataset에 대한 type, data_root, ann_file, img_prefix 환경 파라미터 수정. \n","cfg.data.train.type = 'KittyTinyDataset'\n","cfg.data.train.data_root = '/content/kitti_tiny/'\n","cfg.data.train.ann_file = 'train.txt'\n","cfg.data.train.img_prefix = 'training/image_2'\n","\n","cfg.data.val.type = 'KittyTinyDataset'\n","cfg.data.val.data_root = '/content/kitti_tiny/'\n","cfg.data.val.ann_file = 'val.txt'\n","cfg.data.val.img_prefix = 'training/image_2'\n","\n","cfg.data.test.type = 'KittyTinyDataset'\n","cfg.data.test.data_root = '/content/kitti_tiny/'\n","cfg.data.test.ann_file = 'val.txt'\n","cfg.data.test.img_prefix = 'training/image_2'\n","\n","# class의 갯수 수정. \n","cfg.model.roi_head.bbox_head.num_classes = 4\n","# pretrained 모델\n","cfg.load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n","\n","# 학습 weight 파일로 로그를 저장하기 위한 디렉토리 설정. \n","cfg.work_dir = './tutorial_exps'\n","\n","# 학습율 변경 환경 파라미터 설정. \n","cfg.optimizer.lr = 0.02 / 8\n","\n","cfg.lr_config.warmup = None\n","cfg.log_config.interval = 10\n","\n","# config 수행 시마다 policy값이 없어지는 bug로 인하여 설정. \n","cfg.lr_config.policy = 'step'\n","\n","# Change the evaluation metric since we use customized dataset.\n","cfg.evaluation.metric = 'mAP'\n","# We can set the evaluation interval to reduce the evaluation times\n","cfg.evaluation.interval = 12\n","# We can set the checkpoint saving interval to reduce the storage cost\n","cfg.checkpoint_config.interval = 12\n","\n","# Set seed thus the results are more reproducible\n","cfg.seed = 0\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","\n","# ConfigDict' object has no attribute 'device 오류 발생시 반드시 설정 필요. https://github.com/open-mmlab/mmdetection/issues/7901\n","cfg.device='cuda'\n","\n","\n","# We can initialize the logger for training and have a look\n","# at the final config used for training\n","print(f'Config:\\n{cfg.pretty_text}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"agaAG0i1Jba0"},"source":[]},{"cell_type":"markdown","metadata":{"id":"zIgw7CSOqUxS"},"source":["### Config에서 설정한 Dataset과 Model, 동적 학습율, Pipeline 설정에 따라 모델 학습 수행. \n","\n","* train용 Dataset을 생성하고 이를 이용하여 학습 수행. "]},{"cell_type":"code","metadata":{"id":"OhYoe1KSk5dC"},"source":["from mmdet.datasets import build_dataset\n","from mmdet.models import build_detector\n","from mmdet.apis import train_detector\n","\n","# train용 Dataset 생성. \n","datasets = [build_dataset(cfg.data.train)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOxPgJMCsuGn"},"source":["datasets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8D4Q1CfjNoY"},"source":["datasets[0].CLASSES"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQZbvPJxss-w"},"source":["model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n","model.CLASSES = datasets[0].CLASSES"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ccn2TffRnpu1"},"source":["# 주의, config에 pretrained 모델 지정이 상대 경로로 설정됨 cfg.load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n","# 아래와 같이 %cd mmdetection 지정 필요. \n"," \n","%cd mmdetection \n","\n","mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n","# epochs는 config의 runner 파라미터로 지정됨. 기본 12회 \n","train_detector(model, datasets, cfg, distributed=False, validate=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lRjzWDXYzqdw"},"source":["### 학습된 model을 이용하여 inference 수행. "]},{"cell_type":"code","metadata":{"id":"ihB1s7N-wT9g"},"source":["from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n","\n","# BGR Image 사용 \n","img = cv2.imread('/content/kitti_tiny/training/image_2/000068.jpeg')\n","\n","model.cfg = cfg\n","\n","result = inference_detector(model, img)\n","show_result_pyplot(model, img, result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZnZYtHYqt3oi"},"source":["### 학습된 모델을 이용하여 Video Detection 수행하기"]},{"cell_type":"code","metadata":{"id":"9Jd3VlBFz3Qt"},"source":["%cd /content\n","!mkdir /content/data\n","!wget -O /content/data/the_rock_chase.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/the_rock_chase.mp4?raw=true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hwv5xpbjQqMp"},"source":["CLASSES = ('Car', 'Truck', 'Pedestrian', 'Cyclist')\n","labels_to_names_seq = {i:k for i, k in enumerate(CLASSES)}\n","labels_to_names_seq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idxVvWJbQEIg"},"source":["CLASSES = ('Car', 'Truck', 'Pedestrian', 'Cyclist')\n","cat2label = {k:i for i, k in enumerate(CLASSES)}\n","\n","def get_detected_img(model, img_array,  score_threshold=0.3, is_print=True):\n","  # 인자로 들어온 image_array를 복사. \n","  draw_img = img_array.copy()\n","  bbox_color=(0, 255, 0)\n","  text_color=(0, 0, 255)\n","\n","  # model과 image array를 입력 인자로 inference detection 수행하고 결과를 results로 받음. \n","  # results는 80개의 2차원 array(shape=(오브젝트갯수, 5))를 가지는 list. \n","  results = inference_detector(model, img_array)\n","\n","  # 80개의 array원소를 가지는 results 리스트를 loop를 돌면서 개별 2차원 array들을 추출하고 이를 기반으로 이미지 시각화 \n","  # results 리스트의 위치 index가 바로 COCO 매핑된 Class id. 여기서는 result_ind가 class id\n","  # 개별 2차원 array에 오브젝트별 좌표와 class confidence score 값을 가짐. \n","  for result_ind, result in enumerate(results):\n","    # 개별 2차원 array의 row size가 0 이면 해당 Class id로 값이 없으므로 다음 loop로 진행. \n","    if len(result) == 0:\n","      continue\n","    \n","    # 2차원 array에서 5번째 컬럼에 해당하는 값이 score threshold이며 이 값이 함수 인자로 들어온 score_threshold 보다 낮은 경우는 제외. \n","    result_filtered = result[np.where(result[:, 4] > score_threshold)]\n","    \n","    # 해당 클래스 별로 Detect된 여러개의 오브젝트 정보가 2차원 array에 담겨 있으며, 이 2차원 array를 row수만큼 iteration해서 개별 오브젝트의 좌표값 추출. \n","    for i in range(len(result_filtered)):\n","      # 좌상단, 우하단 좌표 추출. \n","      left = int(result_filtered[i, 0])\n","      top = int(result_filtered[i, 1])\n","      right = int(result_filtered[i, 2])\n","      bottom = int(result_filtered[i, 3])\n","      caption = \"{}: {:.4f}\".format(labels_to_names_seq[result_ind], result_filtered[i, 4])\n","      cv2.rectangle(draw_img, (left, top), (right, bottom), color=bbox_color, thickness=2)\n","      cv2.putText(draw_img, caption, (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.37, text_color, 1)\n","      if is_print:\n","        print(caption)\n","\n","  return draw_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_48aSaJQ7Y-"},"source":["import time\n","\n","def do_detected_video(model, input_path, output_path, score_threshold, do_print=True):\n","    \n","    cap = cv2.VideoCapture(input_path)\n","\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","\n","    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size) \n","\n","    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print('총 Frame 갯수:', frame_cnt)\n","    btime = time.time()\n","    while True:\n","        hasFrame, img_frame = cap.read()\n","        if not hasFrame:\n","            print('더 이상 처리할 frame이 없습니다.')\n","            break\n","        stime = time.time()\n","        img_frame = get_detected_img(model, img_frame,  score_threshold=score_threshold, is_print=False)\n","        if do_print:\n","          print('frame별 detection 수행 시간:', round(time.time() - stime, 4))\n","        vid_writer.write(img_frame)\n","    # end of while loop\n","\n","    vid_writer.release()\n","    cap.release()\n","\n","    print('최종 detection 완료 수행 시간:', round(time.time() - btime, 4))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"czwNkF8CRAG3"},"source":["do_detected_video(model, '/content/data/the_rock_chase.mp4', '/content/data/the_rock_chase_out1.mp4', score_threshold=0.4, do_print=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yKkrUfrPRL4_"},"source":[],"execution_count":null,"outputs":[]}]}
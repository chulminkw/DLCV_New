{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mm_faster_rcnn_inference.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN/bV+SG2YmWgCygl68c7uF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TRvHk7ZOQb3D"},"source":["### MMDetection 설치\n","* mmcv를 설치하는데 약 10분 정도의 시간이 소요"]},{"cell_type":"code","metadata":{"id":"JbciaaGZV__9"},"source":["import torch\n","print(torch.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DpsE9kPJV4eD"},"source":["# mmcv를 위해서 mmcv-full을 설치해야 함. \n","!pip install mmcv-full"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"99m89ceiizfW"},"source":["!git clone https://github.com/open-mmlab/mmdetection.git\n","!cd mmdetection; python setup.py install"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlIOlLLLjAP7"},"source":["# 아래를 수행하기 전에 kernel을 restart 해야 함. \n","from mmdet.apis import init_detector, inference_detector\n","import mmcv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t_dDdanyVrJ2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qHm73mVCQmpc"},"source":["### MS-COCO 데이터 기반으로 Faster RCNN Pretrained 모델을 활용하여 Inference 수행\n","* Faster RCNN Pretrained 모델 다운로드\n","* Faster RCNN용 Config 파일 설정.  \n","* Inference 용 모델을 생성하고, Inference 적용"]},{"cell_type":"code","metadata":{"id":"Gs162gTppmTh"},"source":["# pretrained weight 모델을 다운로드 받기 위해서 mmdetection/checkpoints 디렉토리를 만듬. \n","!cd mmdetection; mkdir checkpoints"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BvBLA2ecqJsV"},"source":["!wget -O /content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YbETJ0zYh_bf"},"source":["!ls -lia /content/mmdetection/checkpoints"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHyGQYXpoM_u"},"source":["# config 파일을 설정하고, 다운로드 받은 pretrained 모델을 checkpoint로 설정. \n","config_file = '/content/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n","checkpoint_file = '/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUgqp_sOpPKN"},"source":["# config 파일과 pretrained 모델을 기반으로 Detector 모델을 생성. \n","from mmdet.apis import init_detector, inference_detector\n","\n","model = init_detector(config_file, checkpoint_file, device='cuda:0')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ok9vjFcy7NK"},"source":["# mmdetection은 상대 경로를 인자로 주면 무조건 mmdetection 디렉토리를 기준으로 함. \n","%cd mmdetection\n","\n","from mmdet.apis import init_detector, inference_detector\n","\n","# init_detector() 인자로 config와 checkpoint를 입력함. \n","model = init_detector(config='configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py', checkpoint='checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4-31iMTozQmD"},"source":["%cd /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DwPX9OslRgc"},"source":["import cv2\n","import matplotlib.pyplot as plt\n","img = '/content/mmdetection/demo/demo.jpg'\n","\n","img_arr  = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_arr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1U7BfoXrpR4l"},"source":["img = '/content/mmdetection/demo/demo.jpg'\n","# inference_detector의 인자로 string(file경로), ndarray가 단일 또는 list형태로 입력 될 수 있음. \n","results = inference_detector(model, img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dkWvvhR6qvcZ"},"source":["type(results), len(results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zzkO3S5osBgV"},"source":["# results는 list형으로 coco class의  0부터 79까지 class_id별로 80개의 array를 가짐. \n","# 개별 array들은 각 클래스별로 5개의 값(좌표값과 class별로 confidence)을 가짐. 개별 class별로 여러개의 좌표를 가지면 여러개의 array가 생성됨. \n","# 좌표는 좌상단(xmin, ymin), 우하단(xmax, ymax) 기준. \n","# 개별 array의 shape는 (Detection된 object들의 수, 5(좌표와 confidence)) 임\n","\n","results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DlHzIIj-q1p6"},"source":["results[0].shape, results[1].shape, results[2].shape, results[3].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJDIEqGwq9wu"},"source":["from mmdet.apis import show_result_pyplot\n","# inference 된 결과를 원본 이미지에 적용하여 새로운 image로 생성(bbox 처리된 image)\n","# Default로 score threshold가 0.3 이상인 Object들만 시각화 적용. show_result_pyplot은 model.show_result()를 호출. \n","show_result_pyplot(model, img, results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BKKCgICT3fiR"},"source":["### Model의 Config 설정 확인하기"]},{"cell_type":"code","metadata":{"id":"F1daKttM0f8a"},"source":["model.__dict__"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PAv-3gZI1Tlx"},"source":["#print(model.cfg)\n","print(model.cfg.pretty_text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZbQletok3lat"},"source":["### array를 inference_detector()에 입력할 경우에는 원본 array를 BGR 형태로 입력 필요(RGB 변환은 내부에서 수행하므로 BGR로 입력 필요)"]},{"cell_type":"code","metadata":{"id":"qJVKVJ8izkkR"},"source":["import cv2\n","\n","# RGB가 아닌 BGR로 입력\n","img_arr = cv2.imread('/content/mmdetection/demo/demo.jpg')\n","results = inference_detector(model, img_arr)\n","\n","show_result_pyplot(model, img_arr, results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XNWbL1aoQeHb"},"source":["### show_result_pyplot()을 이용하지 않고, inference 결과를 image로 표현하기\n","* model과 image array를 입력하면 해당 image를 detect하고 bbox 처리해주는 get_detected_img() 함수 생성. \n","* COCO 클래스 매핑은 0 부터 순차적으로 적용됨. \n","* results에 들어있는 array 값이 없는 경우는 해당 list의 index에 해당하는 class id값으로 object가 Detection되지 않은 것임.  \n","* 개별 class의 score threshold가 낮은 값은 제외. "]},{"cell_type":"code","metadata":{"id":"3BsbdPe9WFY6"},"source":["# 0부터 순차적으로 클래스 매핑된 label 적용. \n","labels_to_names_seq = {0:'person',1:'bicycle',2:'car',3:'motorbike',4:'aeroplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',10:'fire hydrant',\n","                        11:'stop sign',12:'parking meter',13:'bench',14:'bird',15:'cat',16:'dog',17:'horse',18:'sheep',19:'cow',20:'elephant',\n","                        21:'bear',22:'zebra',23:'giraffe',24:'backpack',25:'umbrella',26:'handbag',27:'tie',28:'suitcase',29:'frisbee',30:'skis',\n","                        31:'snowboard',32:'sports ball',33:'kite',34:'baseball bat',35:'baseball glove',36:'skateboard',37:'surfboard',38:'tennis racket',39:'bottle',40:'wine glass',\n","                        41:'cup',42:'fork',43:'knife',44:'spoon',45:'bowl',46:'banana',47:'apple',48:'sandwich',49:'orange',50:'broccoli',\n","                        51:'carrot',52:'hot dog',53:'pizza',54:'donut',55:'cake',56:'chair',57:'sofa',58:'pottedplant',59:'bed',60:'diningtable',\n","                        61:'toilet',62:'tvmonitor',63:'laptop',64:'mouse',65:'remote',66:'keyboard',67:'cell phone',68:'microwave',69:'oven',70:'toaster',\n","                        71:'sink',72:'refrigerator',73:'book',74:'clock',75:'vase',76:'scissors',77:'teddy bear',78:'hair drier',79:'toothbrush' }\n","\n","labels_to_names = {1:'person',2:'bicycle',3:'car',4:'motorcycle',5:'airplane',6:'bus',7:'train',8:'truck',9:'boat',10:'traffic light',\n","                    11:'fire hydrant',12:'street sign',13:'stop sign',14:'parking meter',15:'bench',16:'bird',17:'cat',18:'dog',19:'horse',20:'sheep',\n","                    21:'cow',22:'elephant',23:'bear',24:'zebra',25:'giraffe',26:'hat',27:'backpack',28:'umbrella',29:'shoe',30:'eye glasses',\n","                    31:'handbag',32:'tie',33:'suitcase',34:'frisbee',35:'skis',36:'snowboard',37:'sports ball',38:'kite',39:'baseball bat',40:'baseball glove',\n","                    41:'skateboard',42:'surfboard',43:'tennis racket',44:'bottle',45:'plate',46:'wine glass',47:'cup',48:'fork',49:'knife',50:'spoon',\n","                    51:'bowl',52:'banana',53:'apple',54:'sandwich',55:'orange',56:'broccoli',57:'carrot',58:'hot dog',59:'pizza',60:'donut',\n","                    61:'cake',62:'chair',63:'couch',64:'potted plant',65:'bed',66:'mirror',67:'dining table',68:'window',69:'desk',70:'toilet',\n","                    71:'door',72:'tv',73:'laptop',74:'mouse',75:'remote',76:'keyboard',77:'cell phone',78:'microwave',79:'oven',80:'toaster',\n","                    81:'sink',82:'refrigerator',83:'blender',84:'book',85:'clock',86:'vase',87:'scissors',88:'teddy bear',89:'hair drier',90:'toothbrush',\n","                    91:'hair brush'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WtZxYMcZX2X8"},"source":["import numpy as np\n","\n","# np.where 사용법 예시.\n","arr1 = np.array([[3.75348572e+02, 1.19171005e+02, 3.81950867e+02, 1.34460617e+02,\n","         1.35454759e-01],\n","        [5.32362000e+02, 1.09554726e+02, 5.40526550e+02, 1.25222633e+02,\n","         8.88786465e-01],\n","        [3.61124298e+02, 1.09049202e+02, 3.68625610e+02, 1.22483063e+02,\n","         7.20717013e-02]], dtype=np.float32)\n","print(arr1.shape)\n","\n","arr1_filtered = arr1[np.where(arr1[:, 4] > 0.1)]\n","print('### arr1_filtered:', arr1_filtered, arr1_filtered.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rhqh0gmM4vH_"},"source":["np.where(arr1[:, 4] > 0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WG9q57paRkM1"},"source":["# model과 원본 이미지 array, filtering할 기준 class confidence score를 인자로 가지는 inference 시각화용 함수 생성. \n","def get_detected_img(model, img_array,  score_threshold=0.3, is_print=True):\n","  # 인자로 들어온 image_array를 복사. \n","  draw_img = img_array.copy()\n","  bbox_color=(0, 255, 0)\n","  text_color=(0, 0, 255)\n","\n","  # model과 image array를 입력 인자로 inference detection 수행하고 결과를 results로 받음. \n","  # results는 80개의 2차원 array(shape=(오브젝트갯수, 5))를 가지는 list. \n","  results = inference_detector(model, img_array)\n","\n","  # 80개의 array원소를 가지는 results 리스트를 loop를 돌면서 개별 2차원 array들을 추출하고 이를 기반으로 이미지 시각화 \n","  # results 리스트의 위치 index가 바로 COCO 매핑된 Class id. 여기서는 result_ind가 class id\n","  # 개별 2차원 array에 오브젝트별 좌표와 class confidence score 값을 가짐. \n","  for result_ind, result in enumerate(results):\n","    # 개별 2차원 array의 row size가 0 이면 해당 Class id로 값이 없으므로 다음 loop로 진행. \n","    if len(result) == 0:\n","      continue\n","    \n","    # 2차원 array에서 5번째 컬럼에 해당하는 값이 score threshold이며 이 값이 함수 인자로 들어온 score_threshold 보다 낮은 경우는 제외. \n","    result_filtered = result[np.where(result[:, 4] > score_threshold)]\n","    \n","    # 해당 클래스 별로 Detect된 여러개의 오브젝트 정보가 2차원 array에 담겨 있으며, 이 2차원 array를 row수만큼 iteration해서 개별 오브젝트의 좌표값 추출. \n","    for i in range(len(result_filtered)):\n","      # 좌상단, 우하단 좌표 추출. \n","      left = int(result_filtered[i, 0])\n","      top = int(result_filtered[i, 1])\n","      right = int(result_filtered[i, 2])\n","      bottom = int(result_filtered[i, 3])\n","      caption = \"{}: {:.4f}\".format(labels_to_names_seq[result_ind], result_filtered[i, 4])\n","      cv2.rectangle(draw_img, (left, top), (right, bottom), color=bbox_color, thickness=2)\n","      cv2.putText(draw_img, caption, (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.37, text_color, 1)\n","      if is_print:\n","        print(caption)\n","\n","  return draw_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0DPDQ33mJMg"},"source":["import matplotlib.pyplot as plt\n","\n","img_arr = cv2.imread('/content/mmdetection/demo/demo.jpg')\n","detected_img = get_detected_img(model, img_arr,  score_threshold=0.3, is_print=True)\n","# detect 입력된 이미지는 bgr임. 이를 최종 출력시 rgb로 변환 \n","detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(detected_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TvqsrQWcWmSH"},"source":["!mkdir data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8TEyDTWRkVf"},"source":["!wget -O /content/data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg\n","!ls -lia /content/data/beatles01.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4bRWFILRkaK"},"source":["img_arr = cv2.imread('/content/data/beatles01.jpg')\n","detected_img = get_detected_img(model, img_arr,  score_threshold=0.5, is_print=True)\n","# detect 입력된 이미지는 bgr임. 이를 최종 출력시 rgb로 변환 \n","detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(detected_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3FraDdoVWw1y"},"source":["### Video Inference 수행\n","* mmdetection의 video_demo.py 대로 Video inference 수행시 image 처리 시간이 상대적으로 오래 걸림. \n","* 이미지 처리 로직을 변경하여 적용"]},{"cell_type":"code","metadata":{"id":"00k77eI3045G"},"source":["!wget -O /content/data/John_Wick_small.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/John_Wick_small.mp4?raw=true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ugo0hmp0YJ0D"},"source":["from mmdet.apis import init_detector, inference_detector\n","import mmcv\n","\n","config_file = '/content/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n","checkpoint_file = '/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n","model = init_detector(config_file, checkpoint_file, device='cuda:0')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EzwaONdFcxaq"},"source":["# https://github.com/open-mmlab/mmdetection/blob/master/demo/video_demo.py 대로 video detection 수행. \n","\n","import cv2\n","\n","video_reader = mmcv.VideoReader('/content/data/John_Wick_small.mp4')\n","video_writer = None\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","video_writer = cv2.VideoWriter('/content/data/John_Wick_small_out1.mp4', fourcc, video_reader.fps,(video_reader.width, video_reader.height))\n","\n","for frame in mmcv.track_iter_progress(video_reader):\n","  result = inference_detector(model, frame)\n","  frame = model.show_result(frame, result, score_thr=0.4)\n","\n","  video_writer.write(frame)\n","\n","if video_writer:\n","        video_writer.release()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sJvWNaicLjrY"},"source":["### Custom된 frame처리 로직을 적용하여 Video Inference 수행.\n","* 기존에 사용한 get_detected_img()를 그대로 사용함. "]},{"cell_type":"code","metadata":{"id":"-EVLPJozgzUC"},"source":["# model과 원본 이미지 array, filtering할 기준 class confidence score를 인자로 가지는 inference 시각화용 함수 생성. \n","import numpy as np\n","\n","# 0부터 순차적으로 클래스 매핑된 label 적용. \n","labels_to_names_seq = {0:'person',1:'bicycle',2:'car',3:'motorbike',4:'aeroplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',10:'fire hydrant',\n","                        11:'stop sign',12:'parking meter',13:'bench',14:'bird',15:'cat',16:'dog',17:'horse',18:'sheep',19:'cow',20:'elephant',\n","                        21:'bear',22:'zebra',23:'giraffe',24:'backpack',25:'umbrella',26:'handbag',27:'tie',28:'suitcase',29:'frisbee',30:'skis',\n","                        31:'snowboard',32:'sports ball',33:'kite',34:'baseball bat',35:'baseball glove',36:'skateboard',37:'surfboard',38:'tennis racket',39:'bottle',40:'wine glass',\n","                        41:'cup',42:'fork',43:'knife',44:'spoon',45:'bowl',46:'banana',47:'apple',48:'sandwich',49:'orange',50:'broccoli',\n","                        51:'carrot',52:'hot dog',53:'pizza',54:'donut',55:'cake',56:'chair',57:'sofa',58:'pottedplant',59:'bed',60:'diningtable',\n","                        61:'toilet',62:'tvmonitor',63:'laptop',64:'mouse',65:'remote',66:'keyboard',67:'cell phone',68:'microwave',69:'oven',70:'toaster',\n","                        71:'sink',72:'refrigerator',73:'book',74:'clock',75:'vase',76:'scissors',77:'teddy bear',78:'hair drier',79:'toothbrush' }\n","\n","def get_detected_img(model, img_array,  score_threshold=0.3, is_print=True):\n","  # 인자로 들어온 image_array를 복사. \n","  draw_img = img_array.copy()\n","  bbox_color=(0, 255, 0)\n","  text_color=(0, 0, 255)\n","\n","  # model과 image array를 입력 인자로 inference detection 수행하고 결과를 results로 받음. \n","  # results는 80개의 2차원 array(shape=(오브젝트갯수, 5))를 가지는 list. \n","  results = inference_detector(model, img_array)\n","\n","  # 80개의 array원소를 가지는 results 리스트를 loop를 돌면서 개별 2차원 array들을 추출하고 이를 기반으로 이미지 시각화 \n","  # results 리스트의 위치 index가 바로 COCO 매핑된 Class id. 여기서는 result_ind가 class id\n","  # 개별 2차원 array에 오브젝트별 좌표와 class confidence score 값을 가짐. \n","  for result_ind, result in enumerate(results):\n","    # 개별 2차원 array의 row size가 0 이면 해당 Class id로 값이 없으므로 다음 loop로 진행. \n","    if len(result) == 0:\n","      continue\n","    \n","    # 2차원 array에서 5번째 컬럼에 해당하는 값이 score threshold이며 이 값이 함수 인자로 들어온 score_threshold 보다 낮은 경우는 제외. \n","    result_filtered = result[np.where(result[:, 4] > score_threshold)]\n","    \n","    # 해당 클래스 별로 Detect된 여러개의 오브젝트 정보가 2차원 array에 담겨 있으며, 이 2차원 array를 row수만큼 iteration해서 개별 오브젝트의 좌표값 추출. \n","    for i in range(len(result_filtered)):\n","      # 좌상단, 우하단 좌표 추출. \n","      left = int(result_filtered[i, 0])\n","      top = int(result_filtered[i, 1])\n","      right = int(result_filtered[i, 2])\n","      bottom = int(result_filtered[i, 3])\n","      caption = \"{}: {:.4f}\".format(labels_to_names_seq[result_ind], result_filtered[i, 4])\n","      cv2.rectangle(draw_img, (left, top), (right, bottom), color=bbox_color, thickness=2)\n","      cv2.putText(draw_img, caption, (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.37, text_color, 1)\n","      if is_print:\n","        print(caption)\n","\n","  return draw_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLdfdrYQfPwF"},"source":["import time\n","\n","def do_detected_video(model, input_path, output_path, score_threshold, do_print=True):\n","    \n","    cap = cv2.VideoCapture(input_path)\n","\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","\n","    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size) \n","\n","    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print('총 Frame 갯수:', frame_cnt)\n","    btime = time.time()\n","    while True:\n","        hasFrame, img_frame = cap.read()\n","        if not hasFrame:\n","            print('더 이상 처리할 frame이 없습니다.')\n","            break\n","        stime = time.time()\n","        img_frame = get_detected_img(model, img_frame,  score_threshold=score_threshold, is_print=False)\n","        if do_print:\n","          print('frame별 detection 수행 시간:', round(time.time() - stime, 4))\n","        vid_writer.write(img_frame)\n","    # end of while loop\n","\n","    vid_writer.release()\n","    cap.release()\n","\n","    print('최종 detection 완료 수행 시간:', round(time.time() - btime, 4))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ku0dJAsLhKtA"},"source":["do_detected_video(model, '/content/data/John_Wick_small.mp4', '/content/data/John_Wick_small_out2.mp4', score_threshold=0.4, do_print=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWzbe1ar1Plo"},"source":[""],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf113] *","language":"python","name":"conda-env-tf113-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"opencv_mask_rcnn_inference.ipynb","provenance":[{"file_id":"16eqm3myOQO7xFiTxsBa4s_WHTlkhcKGm","timestamp":1623629911768}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"aF59-bOyQe_u"},"source":["### OpenCV DNN 패키지를 이용하여 MASK R-CNN 기반의 Object Detection/Instance Segmentation 수행\n","* Tensorflow 에서 Pretrained 된 모델 파일을 OpenCV에서 로드하여 이미지와 영상에 대한 Object Detection 수행. "]},{"cell_type":"markdown","metadata":{"id":"q3mgq_wnQe_z"},"source":["#### 입력 이미지로 사용될 이미지 다운로드/보기"]},{"cell_type":"code","metadata":{"id":"veqbrEUwIcOc"},"source":["!mkdir /content/data\n","!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5W1OhdomQe_0"},"source":["import cv2\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","img = cv2.imread('./data/beatles01.jpg')\n","img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","print('image shape:', img.shape)\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ReiyE6qXQe_3"},"source":["#### Tensorflow에서 Pretrained 된 Inference모델(Frozen graph)와 환경파일을 다운로드 받은 후 이를 이용해 OpenCV에서 Inference 모델 생성\n","* https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API 에 다운로드 URL 있음.\n","* pretrained 모델은 http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz 에서 다운로드 후 압축 해제\n","* pretrained 모델을 위한 환경 파일은 https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt 에서 다운로드 \n","* download된 모델 파일과 config 파일을 인자로 하여 inference 모델을 DNN에서 로딩함. \n"]},{"cell_type":"code","metadata":{"id":"1X4mTJRhQe_4"},"source":["!mkdir ./pretrained\n","!wget -O ./pretrained/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz\n","!wget -O ./pretrained/config_mask_graph.pbtxt https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mn95ff8JuX3"},"source":["!tar -xvf ./pretrained/mask*.tar.gz -C ./pretrained "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r0LFdN3MQe_5"},"source":["!pwd\n","!ls -lia ./pretrained/mask_rcnn_inception_v2_coco_2018_01_28"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZsnnERDQe_7"},"source":["#### dnn에서 readNetFromTensorflow()로 tensorflow inference 모델을 로딩 후 Inference 수행\n","* cv_net.forward() 수행 시 Bounding box Inference(bbox regression, bbox classification)과 mask inference 결과를 함께 출력하기 위해 layer명 detection_out_final, detection_masks 결과 가져옴"]},{"cell_type":"code","metadata":{"id":"Yqvx54DBQe_7"},"source":["cv_net = cv2.dnn.readNetFromTensorflow('./pretrained/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb', \n","                                     './pretrained/config_mask_graph.pbtxt')\n","blob = cv2.dnn.blobFromImage(img , swapRB=True, crop=False)\n","cv_net.setInput(blob)\n","\n","# Bounding box 정보는 detection_out_final layer에서 mask 정보는 detection_masks layer에서 추출. \n","boxes, masks = cv_net.forward(['detection_out_final', 'detection_masks'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"35FGFN_s6gRB"},"source":["layer_names = cv_net.getLayerNames()\n","layer_names"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wf_DxJfaQe_9"},"source":["#### coco 데이터 세트의 클래스id별 클래스명 지정. "]},{"cell_type":"code","metadata":{"id":"brOMVMUJQe_-"},"source":["# coco dataset의 클래스 ID별 클래스명 매핑\n","labels_to_names_seq= {0:'person',1:'bicycle',2:'car',3:'motorcycle',4:'airplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',\n","                    10:'fire hydrant',11:'street sign',12:'stop sign',13:'parking meter',14:'bench',15:'bird',16:'cat',17:'dog',18:'horse',19:'sheep',\n","                    20:'cow',21:'elephant',22:'bear',23:'zebra',24:'giraffe',25:'hat',26:'backpack',27:'umbrella',28:'shoe',29:'eye glasses',\n","                    30:'handbag',31:'tie',32:'suitcase',33:'frisbee',34:'skis',35:'snowboard',36:'sports ball',37:'kite',38:'baseball bat',39:'baseball glove',\n","                    40:'skateboard',41:'surfboard',42:'tennis racket',43:'bottle',44:'plate',45:'wine glass',46:'cup',47:'fork',48:'knife',49:'spoon',\n","                    50:'bowl',51:'banana',52:'apple',53:'sandwich',54:'orange',55:'broccoli',56:'carrot',57:'hot dog',58:'pizza',59:'donut',\n","                    60:'cake',61:'chair',62:'couch',63:'potted plant',64:'bed',65:'mirror',66:'dining table',67:'window',68:'desk',69:'toilet',\n","                    70:'door',71:'tv',72:'laptop',73:'mouse',74:'remote',75:'keyboard',76:'cell phone',77:'microwave',78:'oven',79:'toaster',\n","                    80:'sink',81:'refrigerator',82:'blender',83:'book',84:'clock',85:'vase',86:'scissors',87:'teddy bear',88:'hair drier',89:'toothbrush',\n","                    90:'hair brush'}\n","\n","\n","\n","#masking 시 클래스별 컬러 적용\n","colors = list(\n","    [[0, 255, 0],\n","     [0, 0, 255],\n","     [255, 0, 0],\n","     [0, 255, 255],\n","     [255, 255, 0],\n","     [255, 0, 255],\n","     [80, 70, 180],\n","     [250, 80, 190],\n","     [245, 145, 50],\n","     [70, 150, 250],\n","     [50, 190, 190]] )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYHEiRKoPKTd"},"source":["# bbox 정보는  찾아낸 object 갯수별로(여기서는 100개), class_id, class confidence score,  bbox 좌표등 7개의 정보로 구성. 개\n","# masking 정보는 object 갯수별로 90개의 coco class 별로 15x15의 masking 으로 구성. \n","print('boxes shape:', boxes.shape, 'masks shape:', masks.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fERbvTLUQfAA"},"source":["#### Detect된 Object에 대해서 bounding box와 mask를 시각화 \n","* 이미지를 mask 설명을 위해서 Detected된 모든 object를 시각화 하지 않고 단 하나의 object만 시각화 수행(iteration을 한번만 수행)"]},{"cell_type":"code","metadata":{"id":"7rp7J6IB-sfl"},"source":["masks[0,0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQFGOwtzZqIk"},"source":["boxes.shape, masks.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9ELBoueQfAB"},"source":["import numpy as np\n","\n","numClasses = masks.shape[1]\n","numDetections = boxes.shape[2]\n","\n","# opencv의 rectangle(), putText() API는 인자로 들어온 IMAGE array에 그대로 수정작업을 수행하므로 bounding box 적용을 위한 \n","# 별도의 image array 생성. \n","draw_img = img_rgb.copy()\n","\n","img_height = draw_img.shape[0]\n","img_width = draw_img.shape[1]\n","\n","conf_threshold = 0.5\n","mask_threshold = 0.3\n","\n","green_color=(0, 255, 0)\n","red_color=(0, 0, 255)\n","\n","# 이미지를 mask 설명을 위해서 iteration을 한번만 수행. \n","#for i in range(numDetections):\n","for i in range(1):\n","    box = boxes[0, 0, i]\n","    mask = masks[i]\n","    score = box[2]\n","    if score > conf_threshold:\n","        classId = int(box[1])\n","        left = int(img_width * box[3])\n","        top = int(img_height * box[4])\n","        right = int(img_width * box[5])\n","        bottom = int(img_height * box[6])\n","\n","        text = \"{}: {:.4f}\".format(labels_to_names_seq[classId], score)\n","        cv2.rectangle(draw_img, (left, top), (right, bottom), green_color, thickness=2 )\n","        cv2.putText(draw_img, text, (left, top-3), cv2.FONT_HERSHEY_SIMPLEX, 0.3, red_color, 1)\n","\n","        #### Detect된 Object에 대한 image mask 처리 수행을 위한 기본 정보 추출. \n","        # 네트웍 모델에서 반환된 detect된 object의 mask 정보 추출\n","        # (100, 90, 15, 15)\n","        classMask = mask[classId]\n","        print('Detect된 classMask shape:', classMask.shape)\n","        # 원본 이미지의 object 크기에 맞춰 mask 크기 scale out \n","        scaled_classMask = cv2.resize(classMask, (right - left + 1, bottom - top + 1))\n","        print('원본 오브젝트 비율로 scale out된 classMask shape:', scaled_classMask.shape)\n","        # 지정된 mask Threshold 값 이상인지 True, False boolean형태의 mask 정보 생성. \n","        s_mask_b = (scaled_classMask > mask_threshold)\n","        print('scaled mask shape:', s_mask_b.shape, 'scaled mask pixel count:', s_mask_b.shape[0]*s_mask_b.shape[1],\n","              'scaled mask true shape:',s_mask_b[s_mask_b==True].shape, \n","              'scaled mask False shape:', s_mask_b[s_mask_b==False].shape)\n","        # mask를 적용할 bounding box 영역의 image 추출\n","        before_mask_roi = draw_img[top:bottom+1, left:right+1]\n","        print('before_mask_roi:', before_mask_roi.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qv4auaemUihv"},"source":["s_mask_b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_REEFl8s8q25"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QSKnUHMM8saB"},"source":["####  Detected된 object에 mask 적용 후 시각화"]},{"cell_type":"code","metadata":{"id":"Ua5V1YN08om0"},"source":["vis_mask = (s_mask_b * 255).astype(\"uint8\")\n","print(vis_mask.shape, vis_mask[vis_mask >= 1], vis_mask[vis_mask >= 1].shape)\n","#Open CV로 원본 Object에 masking 작업 수행\n","instance = cv2.bitwise_and(before_mask_roi, before_mask_roi, mask=vis_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"plu6O1Ev86JY"},"source":["fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(figsize=(8, 8), ncols=5, nrows=1)\n","\n","ax1.set_title('network detected mask')\n","ax1.axis('off')\n","ax1.imshow(classMask)\n","\n","ax2.set_title('resized mask')\n","ax2.axis('off')\n","ax2.imshow(scaled_classMask)\n","\n","\n","ax3.set_title('Before Mask ROI')\n","ax3.axis('off')\n","ax3.imshow(before_mask_roi)\n","\n","ax4.set_title('Vis Mask')\n","ax4.axis('off')\n","ax4.imshow(vis_mask, cmap='gray')\n","\n","ax5.set_title('after Mask ROI')\n","ax5.axis('off')\n","ax5.imshow(instance)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hyz7VUTwERQI"},"source":["#### Detected된 object에 mask를 특정 투명 컬러로 적용후 시각화"]},{"cell_type":"code","metadata":{"id":"W3t6eQTdhzXL"},"source":["draw_img[top:bottom+1, left:right+1].shape, draw_img[top:bottom+1, left:right+1][s_mask_b].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N64QWCdg86PE"},"source":["import numpy as np\n","\n","draw_img = img_rgb.copy()\n","\n","colorIndex = np.random.randint(0, len(colors)-1)\n","color = colors[colorIndex]\n","print(color)\n","after_mask_roi = draw_img[top:bottom+1, left:right+1][s_mask_b]\n","draw_img[top:bottom+1, left:right+1][s_mask_b] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.6 * after_mask_roi).astype(np.uint8)\n","\n","plt.figure(figsize=(6,6))\n","plt.axis('off')\n","plt.title('After Mask color')\n","plt.imshow(draw_img[top:bottom+1, left:right+1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ONfJPHCzEeCS"},"source":["print('object image shape:', draw_img[top:bottom+1, left:right+1].shape)\n","print('boolena object mask:', s_mask_b, s_mask_b.shape)\n","print('object masking boolen index 결과 shape:', draw_img[top:bottom+1, left:right+1][s_mask_b].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHgUiSdJ86Rx"},"source":["print('투명 color 적용 1:', [0.3*color[0], 0.3*color[1], 0.3*color[2]])\n","print('투명 color 적용 2:', 0.6 * after_mask_roi)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZJ9eod3HBv8"},"source":["#### Mask 정보를 이용하여 Detect된 Object에 contour 윤곽선 적용. "]},{"cell_type":"code","metadata":{"id":"kl3xBjYE86UI"},"source":["draw_img_01 = img_rgb.copy()\n","\n","s_mask_i = s_mask_b.astype(np.uint8)\n","contours, hierarchy = cv2.findContours(s_mask_i,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n","cv2.drawContours(draw_img_01[top:bottom+1, left:right+1], contours, -1, color, 1, cv2.LINE_8, hierarchy, 100)\n","\n","plt.figure(figsize=(6,6))\n","plt.axis('off')\n","plt.title('After Mask color')\n","plt.imshow(draw_img_01[top:bottom+1, left:right+1])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_P9ZCzcAHQzk"},"source":["#### Detected된 Object들에 Mask 하여 시각화 "]},{"cell_type":"code","metadata":{"id":"rdrQAwxYQfAC"},"source":["import numpy as np\n","\n","numClasses = masks.shape[1]\n","numDetections = boxes.shape[2]\n","\n","# opencv의 rectangle(), putText() API는 인자로 들어온 IMAGE array에 그대로 수정작업을 수행하므로 bounding box 적용을 위한 \n","# 별도의 image array 생성. \n","draw_img = img.copy()\n","\n","img_height = draw_img.shape[0]\n","img_width = draw_img.shape[1]\n","conf_threshold = 0.5\n","mask_threshold = 0.3\n","\n","green_color=(0, 255, 0)\n","red_color=(0, 0, 255)\n","\n","for i in range(numDetections):\n","    box = boxes[0, 0, i]\n","    mask = masks[i]\n","    score = box[2]\n","    if score > conf_threshold:\n","        classId = int(box[1])\n","        left = int(img_width * box[3])\n","        top = int(img_height * box[4])\n","        right = int(img_width * box[5])\n","        bottom = int(img_height * box[6])\n","\n","        text = \"{}: {:.4f}\".format(labels_to_names_seq[classId], score)\n","        cv2.rectangle(draw_img, (left, top), (right, bottom), green_color, thickness=2 )\n","        cv2.putText(draw_img, text, (left, top-3), cv2.FONT_HERSHEY_SIMPLEX, 0.3, red_color, 1)\n","\n","        #### Detect된 Object에 대한 image mask 처리 수행을 위한 기본 정보 추출. \n","        # 네트웍 모델에서 반환된 detect된 object의 mask 정보 추출\n","        classMask = mask[classId]\n","        print('Detect된 classMask shape:', classMask.shape)\n","        # 원본 이미지의 object 크기에 맞춰 mask 크기 scale out \n","        scaled_classMask = cv2.resize(classMask, (right - left + 1, bottom - top + 1))\n","        print('원본 오브젝트 비율로 scale out된 classMask shape:', scaled_classMask.shape)\n","        # 지정된 mask Threshold 값 이상인지 True, False boolean형태의 mask 정보 생성. \n","        s_mask_b = (scaled_classMask > mask_threshold)\n","        print('scaled mask shape:', s_mask_b.shape, 'scaled mask pixel count:', s_mask_b.shape[0]*s_mask_b.shape[1],\n","              'scaled mask true shape:',s_mask_b[s_mask_b==True].shape, \n","              'scaled mask False shape:', s_mask_b[s_mask_b==False].shape)\n","\n","        # mask를 적용할 bounding box 영역의 image 추출\n","        before_mask_roi = draw_img[top:bottom+1, left:right+1]\n","        print('before_mask_roi:', before_mask_roi.shape)\n","        # Detect된 Object에 mask를 특정 투명 컬러로 적용. \n","        colorIndex = np.random.randint(0, len(colors)-1)\n","        color = colors[colorIndex]\n","        after_mask_roi = draw_img[top:bottom+1, left:right+1][s_mask_b]\n","        draw_img[top:bottom+1, left:right+1][s_mask_b] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.6 * after_mask_roi).astype(np.uint8)\n","        # Detect된 Object에 윤곽선(contour) 적용. \n","        s_mask_i = s_mask_b.astype(np.uint8)\n","        contours, hierarchy = cv2.findContours(s_mask_i,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n","        cv2.drawContours(draw_img[top:bottom+1, left:right+1], contours, -1, color, 1, cv2.LINE_8, hierarchy, 100)\n","\n","plt.figure(figsize=(14, 14))\n","draw_img = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","plt.imshow(draw_img)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tcRWaf6rIGeQ"},"source":["#### 단일 image Segmentation 함수 생성. "]},{"cell_type":"code","metadata":{"id":"eax8p_q9HyIK"},"source":["def get_box_info(box, img_width, img_height):\n","    \n","    classId = int(box[1])\n","    left = int(img_width * box[3])\n","    top = int(img_height * box[4])\n","    right = int(img_width * box[5])\n","    bottom = int(img_height * box[6])\n","    \n","    left = max(0, min(left, img_width - 1))\n","    top = max(0, min(top, img_height - 1))\n","    right = max(0, min(right, img_width - 1))\n","    bottom = max(0, min(bottom, img_height - 1))\n","    \n","    return classId, left, top, right, bottom\n","\n","    \n","def draw_box(img_array, box, img_width, img_height, is_print=False):\n","    green_color=(0, 255, 0)\n","    red_color=(0, 0, 255)\n","    \n","    score = box[2]\n","    classId, left, top, right, bottom = get_box_info(box, img_width, img_height)\n","    text = \"{}: {:.4f}\".format(labels_to_names_seq[classId], score)\n","    \n","    if is_print:\n","        print(\"box:\", box, \"score:\", score, \"classId:\", classId)\n","    \n","    cv2.rectangle(img_array, (left, top), (right, bottom), green_color, thickness=2 )\n","    cv2.putText(img_array, text, (left, top-3), cv2.FONT_HERSHEY_SIMPLEX, 0.5, red_color, thickness=1)\n","    \n","    return img_array\n","    \n","def draw_mask(img_array, box, mask, img_width, img_height, mask_threshold, is_print=False):\n","        \n","        classId, left, top, right, bottom = get_box_info(box, img_width, img_height)\n","        classMask = mask[classId]\n","        # 원본 이미지의 object 크기에 맞춰 mask 크기 scale out \n","        scaled_classMask = cv2.resize(classMask, (right - left + 1, bottom - top + 1))\n","        s_mask_b = (scaled_classMask > mask_threshold)\n","        before_mask_roi = img_array[top:bottom+1, left:right+1]\n","        \n","        # mask를 적용할 bounding box 영역의 image 추출하고 투명 color 적용. \n","        colorIndex = np.random.randint(0, len(colors)-1)\n","        color = colors[colorIndex]\n","        after_mask_roi = img_array[top:bottom+1, left:right+1][s_mask_b]\n","        img_array[top:bottom+1, left:right+1][s_mask_b] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.6 * after_mask_roi).astype(np.uint8)\n","        # Detect된 Object에 윤곽선(contour) 적용. \n","        s_mask_i = s_mask_b.astype(np.uint8)\n","        contours, hierarchy = cv2.findContours(s_mask_i,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n","        cv2.drawContours(img_array[top:bottom+1, left:right+1], contours, -1, color, 1, cv2.LINE_8, hierarchy, 100)\n","        \n","        return img_array"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LUPkZbvcHyNB"},"source":["import time\n","\n","def detect_image_mask_rcnn(cv_net, img_array, conf_threshold, mask_threshold, use_copied_array, is_print=False):\n","    \n","    draw_img = None\n","    if use_copied_array:\n","        draw_img = img_array.copy()\n","        #draw_img = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","    else:\n","        draw_img = img_array\n","        \n","    start_time = time.time()\n","    \n","    blob = cv2.dnn.blobFromImage(img_array, swapRB=True, crop=False)\n","    cv_net.setInput(blob)\n","    boxes, masks = cv_net.forward(['detection_out_final', 'detection_masks'])\n","    \n","    inference_time = time.time() - start_time\n","    if is_print:\n","        print('Segmentation Inference time {0:}'.format(inference_time))\n","\n","    numClasses = masks.shape[1]\n","    numDetections = boxes.shape[2]\n","\n","    img_height = img_array.shape[0]\n","    img_width = img_array.shape[1]\n","    \n","    for i in range(numDetections):\n","        box = boxes[0, 0, i]\n","        mask = masks[i]\n","        score = box[2]\n","        #print(\"score:\", score)\n","        if score > conf_threshold:\n","            draw_box(img_array , box, img_width, img_height, is_print=is_print)\n","            draw_mask(img_array, box, mask, img_width, img_height, mask_threshold, is_print=is_print)\n","    \n","    return img_array"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZ8c1KYVHySZ"},"source":["labels_to_names_seq = {0:'person',1:'bicycle',2:'car',3:'motorcycle',4:'airplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',\n","                    10:'fire hydrant',11:'street sign',12:'stop sign',13:'parking meter',14:'bench',15:'bird',16:'cat',17:'dog',18:'horse',19:'sheep',\n","                    20:'cow',21:'elephant',22:'bear',23:'zebra',24:'giraffe',25:'hat',26:'backpack',27:'umbrella',28:'shoe',29:'eye glasses',\n","                    30:'handbag',31:'tie',32:'suitcase',33:'frisbee',34:'skis',35:'snowboard',36:'sports ball',37:'kite',38:'baseball bat',39:'baseball glove',\n","                    40:'skateboard',41:'surfboard',42:'tennis racket',43:'bottle',44:'plate',45:'wine glass',46:'cup',47:'fork',48:'knife',49:'spoon',\n","                    50:'bowl',51:'banana',52:'apple',53:'sandwich',54:'orange',55:'broccoli',56:'carrot',57:'hot dog',58:'pizza',59:'donut',\n","                    60:'cake',61:'chair',62:'couch',63:'potted plant',64:'bed',65:'mirror',66:'dining table',67:'window',68:'desk',69:'toilet',\n","                    70:'door',71:'tv',72:'laptop',73:'mouse',74:'remote',75:'keyboard',76:'cell phone',77:'microwave',78:'oven',79:'toaster',\n","                    80:'sink',81:'refrigerator',82:'blender',83:'book',84:'clock',85:'vase',86:'scissors',87:'teddy bear',88:'hair drier',89:'toothbrush',\n","                    90:'hair brush'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D4gimrNSHyZZ"},"source":["import os\n","# image 로드 \n","img = cv2.imread('./data/beatles01.jpg')\n","print('image shape:', img.shape)\n","\n","cv_net = cv2.dnn.readNetFromTensorflow('./pretrained/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb', \n","                                     './pretrained/config_mask_graph.pbtxt')\n","\n","img_detected = detect_image_mask_rcnn(cv_net, img, conf_threshold=0.5, mask_threshold=0.3, use_copied_array=True, is_print=True)\n","\n","img_rgb = cv2.cvtColor(img_detected, cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2g4dKR20JqLh"},"source":["#### 다른 이미지 파일에 Segmentation 수행하기"]},{"cell_type":"code","metadata":{"id":"M8a9IDjGIkKO"},"source":["!wget -O ./data/baseball01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/baseball01.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c7YH7nFDQfAC"},"source":["import os\n","# image 로드 \n","img = cv2.imread('./data/baseball01.jpg')\n","print('image shape:', img.shape)\n","\n","cv_net = cv2.dnn.readNetFromTensorflow('./pretrained/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb', \n","                                     './pretrained/config_mask_graph.pbtxt')\n","\n","# 야구공이 mask detect 되지 않아서 conf_threshold와 mask_threshold 를 낮춤. \n","img_detected = detect_image_mask_rcnn(cv_net, img, conf_threshold=0.3, mask_threshold=0.2, use_copied_array=True, is_print=True)\n","\n","img_rgb = cv2.cvtColor(img_detected, cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qCgPmKdUKYYu"},"source":["#### 영상에 Segmentation 적용"]},{"cell_type":"code","metadata":{"id":"G56yd-s6KsSe"},"source":["!wget -O ./data/John_Wick_small.mp4 https://raw.githubusercontent.com/chulminkw/DLCV/master/data/video/John_Wick_small.mp4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Je3_OPIQfAD"},"source":["def detect_video_mask_rcnn(cv_net, input_path, output_path, conf_threshold, mask_threshold,  is_print):\n","    \n","    cap = cv2.VideoCapture(input_path)\n","\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","\n","    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    vid_writer = cv2.VideoWriter(output_path, codec, 24, vid_size) \n","\n","    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print('총 Frame 갯수:', frame_cnt, )\n","\n","    frame_index=0\n","    while True:\n","        hasFrame, img_frame = cap.read()\n","        frame_index += 1\n","        if not hasFrame:\n","            print('더 이상 처리할 frame이 없습니다.')\n","            break\n","        print(\"frame index:{0:}\".format(frame_index), end=\" \")\n","        returned_frame = detect_image_mask_rcnn(cv_net, img_frame, conf_threshold=conf_threshold,\n","                                                mask_threshold=mask_threshold,use_copied_array=False, is_print=is_print)\n","        vid_writer.write(returned_frame)\n","    # end of while loop\n","\n","    vid_writer.release()\n","    cap.release()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_RRDlNMTKgQu"},"source":["cv_net = cv2.dnn.readNetFromTensorflow('./pretrained/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb', \n","                                     './pretrained/config_mask_graph.pbtxt')\n","\n","detect_video_mask_rcnn(cv_net,'/content/data/John_Wick_small.mp4', '/content/data/John_Wick_mask_01.avi',\n","                      conf_threshold=0.5, mask_threshold=0.3, is_print=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qXYrpnY6QfAI"},"source":[""],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1wTFFEFF-nikaOONcOC-i6Ck_f9Ozn7dB","timestamp":1623381607498}],"authorship_tag":"ABX9TyOjaYqQ0KqYyTzgxVkyQBSn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TRvHk7ZOQb3D"},"source":["### MMDetection 설치\n","* 강의 영상에는 pip install mmcv-full로 mmcv를 설치(약 10분 정도의 시간이 소요)\n","* 실습코드는 pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13/index.html 로 변경(설치에 12초 정도 걸림. 2022.09).\n","*  2023년 4월 6일 기준으로 mmdetection이 3.0으로 upgrade됨. 실습 코드는 mmdetection 2.x 기준으므로 mmdetection 2.x 소스코드 설치 필요.\n","* 2024년 9월 colab의 numpy version이 1.24로 upgrade되면서 일부 코드가 동작오류. numpy 1.23 으로 downgrade 적용\n","* 2025년 1월 17일 Colab의 python 버전이 3.10에서 3.11로 버전업 되면서 pytorch 2.0, torchvision 0.15로 변경. mmcv도 !pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html 로 변경."]},{"cell_type":"markdown","source":["#### pytorch, torchvision 다운그레이드"],"metadata":{"id":"F_nNu2bWWg2N"}},{"cell_type":"code","source":["#코랩의 pytorch 버전이 2.x 로 upgrade\n","import torch\n","print(torch.__version__)"],"metadata":{"id":"bVLFyU4_bmoy"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DpsE9kPJV4eD"},"source":["!pip install torch==2.0.0 torchvision==0.15.1  --index-url https://download.pytorch.org/whl/cu118"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### mmcv-full 및 mmdetection 설치"],"metadata":{"id":"13f48TebWm_X"}},{"cell_type":"code","source":["# mmcv를 위해서 mmcv-full을 먼저 설치해야 함. https://mmcv.readthedocs.io/en/latest/get_started/installation.html 설치 과정 참조.\n","!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html"],"metadata":{"id":"RQtJqgDTc-AU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2023년 4월 6일 기준으로 mmdetection이 3.0으로 upgrade됨. 실습 코드는 mmdetection 2.x 기준임.\n","# mmdetection 2.x branch의 소스코드 기반으로 mmdetection 설치 필요.\n","!git clone --branch 2.x https://github.com/open-mmlab/mmdetection.git\n","!cd mmdetection; python setup.py install"],"metadata":{"id":"2nTvh01pc-M5"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlIOlLLLjAP7"},"source":["# 아래를 수행하기 전에 kernel을 restart 해야 함.\n","from mmdet.apis import init_detector, inference_detector\n","import mmcv"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 반드시 numpy downgrade를 mmcv 설치 후에 실행할것.\n","!pip install numpy==1.23"],"metadata":{"id":"5CZzUjXrWtjH"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t_dDdanyVrJ2"},"source":["import torch\n","\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qHm73mVCQmpc"},"source":["### MS-COCO 데이터 기반으로 Mask RCNN Pretrained 모델을 활용하여 Inference 수행\n","* Mask RCNN Pretrained 모델 다운로드\n","* Mask RCNN용 Config 파일 설정.  \n","* Inference 용 모델을 생성하고, Inference 적용"]},{"cell_type":"code","metadata":{"id":"Gs162gTppmTh"},"source":["# pretrained weight 모델을 다운로드 받기 위해서 mmdetection/checkpoints 디렉토리를 만듬.\n","!cd mmdetection; mkdir checkpoints"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BvBLA2ecqJsV"},"source":["!wget -O /content/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth http://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r101_fpn_1x_coco/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YbETJ0zYh_bf"},"source":["!ls -lia /content/mmdetection/checkpoints"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHyGQYXpoM_u"},"source":["# config 파일을 설정하고, 다운로드 받은 pretrained 모델을 checkpoint로 설정.\n","config_file = '/content/mmdetection/configs/mask_rcnn/mask_rcnn_r101_fpn_1x_coco.py'\n","checkpoint_file = '/content/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUgqp_sOpPKN"},"source":["# config 파일과 pretrained 모델을 기반으로 Detector 모델을 생성.\n","from mmdet.apis import init_detector, inference_detector\n","\n","model = init_detector(config_file, checkpoint_file, device='cuda:0')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DwPX9OslRgc"},"source":["import cv2\n","import matplotlib.pyplot as plt\n","img = '/content/mmdetection/demo/demo.jpg'\n","\n","img_arr  = cv2.imread(img)\n","img_arr_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_arr_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1U7BfoXrpR4l"},"source":["img_path = '/content/mmdetection/demo/demo.jpg'\n","# inference_detector의 인자로 string(file경로), ndarray가 단일 또는 list형태로 입력 될 수 있음.\n","results = inference_detector(model, img_arr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KAdCpXVXQC3S"},"source":["from mmdet.apis import show_result_pyplot\n","# inference 된 결과를 원본 이미지에 적용하여 새로운 image로 생성(bbox 처리된 image)\n","# Default로 score threshold가 0.3 이상인 Object들만 시각화 적용. show_result_pyplot은 model.show_result()를 호출.\n","show_result_pyplot(model, img_arr, results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yXcqjkK2jdHA"},"source":["### Inference 결과로 반환되는 results 값 살펴 보기\n","* inference_detector(model, img_path)의 결과로 반환되는 값은 instance segmentation 일 경우 Object Detection 결과에 추가되어 segmentation masking 정보도 함께 반환됨"]},{"cell_type":"code","metadata":{"id":"dkWvvhR6qvcZ"},"source":["type(results), len(results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9pNu_6OfenS"},"source":["results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGjvF2pNQVJI"},"source":["print(type(results[0]), len(results[0]), type(results[1]), len(results[1]) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FdRdB45NQqG1"},"source":["'''results[0]는 list형으로 coco class의  0부터 79까지 class_id별로 80개의 array를 가짐.\n","개별 array들은 각 클래스별로 5개의 값(좌표값과 class별로 confidence)을 가짐. 개별 class별로 여러개의 좌표를 가지면 여러개의 array가 생성됨.\n","좌표는 좌상단(xmin, ymin), 우하단(xmax, ymax) 기준.\n","개별 array의 shape는 (Detection된 object들의 수, 5(좌표와 confidence)) 임\n","'''\n","print(type(results[0][0]), results[0][0].shape, results[0][1].shape, results[0][2].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ou9DI1ayQIvr"},"source":["# results[1]은 masking 정보를 가짐. coco class의  0부터 79까지 class_id 별로 80개의 list를 가짐. 개별 list는 개별 object의 mask 정보를 내부 원소로 가짐.\n","# 개별 object의 mask 정보는 2차원 array로서 image의 height x width 형태를 가짐.\n","print('results[1]의 첫번째 원소의 type과 size:', type(results[1][0]), len(results[1][0]), '두번째 원소 사이즈:', len(results[1][1]), '세번째 원소 사이즈:', len(results[1][2]))\n","print('results[1]의 첫번째 원소 list의 첫번째 원소 type과 shape:', type(results[1][0][0]), results[1][0][0].shape)\n","#print('results[1]의 두번째 원소 list의 첫번째 원소 type과 shape:', type(results[1][1][0]))\n","print('results[1]의 세번째 원소 list의 첫번째/두번째/세번째 원소 shape:', results[1][2][0].shape, results[1][2][1].shape, results[1][2][2].shape)\n","print('image shape:', img_arr.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HM7y-_dS1Yq"},"source":["mask_imsi = results[1][0][0]\n","print(mask_imsi)\n","print(mask_imsi[mask_imsi > 0], mask_imsi[mask_imsi == 0])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mask_imsi.shape"],"metadata":{"id":"sN-7fTm8k4jj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","mask_index = np.where(mask_imsi > 0)"],"metadata":{"id":"LL17XN52k9ar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.array(mask_index)"],"metadata":{"id":"I6vBuTi6laQX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_arr_rgb_copy = img_arr_rgb.copy()\n","img_arr_rgb_copy[mask_index[0], mask_index[1], :] =0\n"],"metadata":{"id":"R59_Vi9rlqXm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 12))\n","plt.imshow(img_arr_rgb_copy)"],"metadata":{"id":"KIwwL6-2l9US"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bipE2MKLOa_b"},"source":["import numpy as np\n","\n","def apply_mask(image, mask, color, alpha=0.5):\n","  for c in range(3):\n","    # mask값이 1일 경우는 원본 pixel값에 컬러 segmentation을 적용하고, 그렇지 않을 경우 원본 pixel값을 그대로 유지.\n","    image[:, :, c] = np.where(mask == 1,\n","                              image[:, :, c] *\n","                              (1 - alpha) + alpha * color[c] * 255,\n","                              image[:, :, c])\n","  return image\n","\n","\n","draw_img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n","masked_image = apply_mask(draw_img, results[1][2][0], (0, 255, 0), alpha=0.6)\n","plt.figure(figsize=(12, 14))\n","plt.imshow(masked_image)\n","plt.axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"trgaz_nOrfl2"},"source":["### Video Detection 실행\n","* mmdetection의 model.show_result()를 실행하여 frame별로 object detect 된 결과를 시각화"]},{"cell_type":"code","metadata":{"id":"vJDIEqGwq9wu"},"source":["!mkdir data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"688qOoVMKH9u"},"source":["!wget -O /content/data/John_Wick_small.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/John_Wick_small.mp4?raw=true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MsM3nWsBKIBe"},"source":["# https://github.com/open-mmlab/mmdetection/blob/master/demo/video_demo.py 대로 video detection 수행.\n","import cv2\n","\n","video_reader = mmcv.VideoReader('/content/data/John_Wick_small.mp4')\n","video_writer = None\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","video_writer = cv2.VideoWriter('/content/data/John_Wick_small_out1.mp4', fourcc, video_reader.fps,(video_reader.width, video_reader.height))\n","\n","for frame in mmcv.track_iter_progress(video_reader):\n","  result = inference_detector(model, frame)\n","  frame = model.show_result(frame, result, score_thr=0.4)\n","\n","  video_writer.write(frame)\n","\n","if video_writer:\n","        video_writer.release()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kZexB8Dvr1kW"},"source":["### segmentation 시각화 함수 직접 작성 후 단일 이미지와 Video inference 수행."]},{"cell_type":"code","metadata":{"id":"ohYU8ottv5Zu"},"source":["# 0부터 순차적으로 클래스 매핑된 label 적용.\n","labels_to_names_seq = {0:'person',1:'bicycle',2:'car',3:'motorbike',4:'aeroplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',10:'fire hydrant',\n","                        11:'stop sign',12:'parking meter',13:'bench',14:'bird',15:'cat',16:'dog',17:'horse',18:'sheep',19:'cow',20:'elephant',\n","                        21:'bear',22:'zebra',23:'giraffe',24:'backpack',25:'umbrella',26:'handbag',27:'tie',28:'suitcase',29:'frisbee',30:'skis',\n","                        31:'snowboard',32:'sports ball',33:'kite',34:'baseball bat',35:'baseball glove',36:'skateboard',37:'surfboard',38:'tennis racket',39:'bottle',40:'wine glass',\n","                        41:'cup',42:'fork',43:'knife',44:'spoon',45:'bowl',46:'banana',47:'apple',48:'sandwich',49:'orange',50:'broccoli',\n","                        51:'carrot',52:'hot dog',53:'pizza',54:'donut',55:'cake',56:'chair',57:'sofa',58:'pottedplant',59:'bed',60:'diningtable',\n","                        61:'toilet',62:'tvmonitor',63:'laptop',64:'mouse',65:'remote',66:'keyboard',67:'cell phone',68:'microwave',69:'oven',70:'toaster',\n","                        71:'sink',72:'refrigerator',73:'book',74:'clock',75:'vase',76:'scissors',77:'teddy bear',78:'hair drier',79:'toothbrush' }\n","\n","colors = list(\n","    [[0, 255, 0],\n","     [0, 0, 255],\n","     [255, 0, 0],\n","     [0, 255, 255],\n","     [255, 255, 0],\n","     [255, 0, 255],\n","     [80, 70, 180],\n","     [250, 80, 190],\n","     [245, 145, 50],\n","     [70, 150, 250]] )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VlaaDH6E2Uel"},"source":["#mask threshold값은 mask_thr_binary=0.5 로 지정되어 있음.\n","print(model.cfg.pretty_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MyzT-CAiv5c7"},"source":["# model과 원본 이미지 array, filtering할 기준 class confidence score를 인자로 가지는 inference 시각화용 함수 생성.\n","# 이미 inference 시 mask boolean값이 들어오므로 mask_threshold 값을 필요하지 않음.\n","def get_detected_img(model, img_array,  score_threshold=0.3, is_print=True):\n","  # 인자로 들어온 image_array를 복사.\n","  draw_img = img_array.copy()\n","  bbox_color=(0, 255, 0)\n","  text_color=(0, 0, 255)\n","\n","  # model과 image array를 입력 인자로 inference detection 수행하고 결과를 results로 받음.\n","  # results는 80개의 2차원 array(shape=(오브젝트갯수, 5))를 가지는 list.\n","  results = inference_detector(model, img_array)\n","  bbox_results = results[0]\n","  seg_results = results[1]\n","\n","  # 80개의 array원소를 가지는 results 리스트를 loop를 돌면서 개별 2차원 array들을 추출하고 이를 기반으로 이미지 시각화\n","  # results 리스트의 위치 index가 바로 COCO 매핑된 Class id. 여기서는 result_ind가 class id\n","  # 개별 2차원 array에 오브젝트별 좌표와 class confidence score 값을 가짐.\n","  for result_ind, bbox_result in enumerate(bbox_results):\n","    # 개별 2차원 array의 row size가 0 이면 해당 Class id로 값이 없으므로 다음 loop로 진행.\n","    if len(bbox_result) == 0:\n","      continue\n","\n","    mask_array_list = seg_results[result_ind]\n","\n","    # 해당 클래스 별로 Detect된 여러개의 오브젝트 정보가 2차원 array에 담겨 있으며, 이 2차원 array를 row수만큼 iteration해서 개별 오브젝트의 좌표값 추출.\n","    for i in range(len(bbox_result)):\n","      # 좌상단, 우하단 좌표 추출.\n","      if bbox_result[i, 4] > score_threshold:\n","        left = int(bbox_result[i, 0])\n","        top = int(bbox_result[i, 1])\n","        right = int(bbox_result[i, 2])\n","        bottom = int(bbox_result[i, 3])\n","        caption = \"{}: {:.4f}\".format(labels_to_names_seq[result_ind], bbox_result[i, 4])\n","        cv2.rectangle(draw_img, (left, top), (right, bottom), color=bbox_color, thickness=2)\n","        cv2.putText(draw_img, caption, (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.37, text_color, 1)\n","        # masking 시각화 적용. class_mask_array는 image 크기 shape의  True/False값을 가지는 2차원 array\n","        class_mask_array = mask_array_list[i]\n","        # 원본 image array에서 mask가 True인 영역만 별도 추출.\n","        masked_roi = draw_img[class_mask_array]\n","        #color를 임의 지정\n","        color_index = np.random.randint(0, len(colors)-1)\n","        # color를 class별로 지정\n","        #color_index = result_ind % len(colors)\n","        color = colors[color_index]\n","        # apply_mask()함수를 적용시 수행 시간이 상대적으로 오래 걸림.\n","        #draw_img = apply_mask(draw_img, class_mask_array, color, alpha=0.4)\n","        # 원본 이미지의 masking 될 영역에 mask를 특정 투명 컬러로 적용\n","        draw_img[class_mask_array] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.6 * masked_roi).astype(np.uint8)\n","        if is_print:\n","          print(caption)\n","\n","  return draw_img\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GiK0Z8sqGi7l"},"source":["img_arr = cv2.imread('/content/mmdetection/demo/demo.jpg')\n","mask_array = results[1][2][0]\n","print('image array shape:', img_arr.shape)\n","print('mask array shape:', mask_array.shape)\n","print('mask true array shape:', mask_array[mask_array].shape)\n","print('masked array shape:', img_arr[results[1][2][0]].shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0TTcVFEu43pQ"},"source":["import matplotlib.pyplot as plt\n","\n","img_arr = cv2.imread('/content/mmdetection/demo/demo.jpg')\n","detected_img = get_detected_img(model, img_arr,  score_threshold=0.3, is_print=True)\n","# detect 입력된 이미지는 bgr임. 이를 최종 출력시 rgb로 변환\n","detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(detected_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kh54JphBA_Fa"},"source":["!mkdir /content/data\n","!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmm3ySEW430t"},"source":["import matplotlib.pyplot as plt\n","\n","img_arr = cv2.imread('/content/data/beatles01.jpg')\n","detected_img = get_detected_img(model, img_arr,  score_threshold=0.3, is_print=True)\n","# detect 입력된 이미지는 bgr임. 이를 최종 출력시 rgb로 변환\n","detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(detected_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7kiQhPu4394"},"source":["import time\n","\n","def do_detected_video(model, input_path, output_path, score_threshold, do_print=True):\n","\n","    cap = cv2.VideoCapture(input_path)\n","\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","\n","    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n","\n","    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print('총 Frame 갯수:', frame_cnt)\n","    btime = time.time()\n","    while True:\n","        hasFrame, img_frame = cap.read()\n","        if not hasFrame:\n","            print('더 이상 처리할 frame이 없습니다.')\n","            break\n","        stime = time.time()\n","        img_frame = get_detected_img(model, img_frame,  score_threshold=score_threshold,is_print=False)\n","        if do_print:\n","          print('frame별 detection 수행 시간:', round(time.time() - stime, 4))\n","        vid_writer.write(img_frame)\n","    # end of while loop\n","\n","    vid_writer.release()\n","    cap.release()\n","\n","    print('최종 detection 완료 수행 시간:', round(time.time() - btime, 4))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mznJS9NKKr03"},"source":["do_detected_video(model, '/content/data/John_Wick_small.mp4', '/content/data/John_Wick_small_out2.mp4', score_threshold=0.4, do_print=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykNwhsR4Kr4h"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWzbe1ar1Plo"},"source":[],"execution_count":null,"outputs":[]}]}
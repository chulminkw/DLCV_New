{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"authorship_tag":"ABX9TyNq4DMPFHHgl1lkwv2U9eiz"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### MMDetection 설치\n* 강의 영상에는 pip install mmcv-full로 mmcv를 설치(약 10분 정도의 시간이 소요)\n* 실습코드는 pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13/index.html 로 변경(설치에 12초 정도 걸림. 2022.09).\n*  2023년 4월 6일 기준으로 mmdetection이 3.0으로 upgrade됨. 실습 코드는 mmdetection 2.x 기준으므로 mmdetection 2.x 소스코드 설치 필요.\n* 2024년 9월 colab의 numpy version이 1.24로 upgrade되면서 일부 코드가 동작오류. numpy 1.23 으로 downgrade 적용\n* 2025년 1월 17일 Colab의 python 버전이 3.10에서 3.11로 버전업 되면서 pytorch 2.0, torchvision 0.15로 변경. mmcv도 !pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html 로 변경.\n* 2025년 8월 25일 Colab의 python 버전이 3.11에서 3.12로 버전업 되면서 더 이상 mmcv-full이 제대로 설치 되지 않음.\n* 이에 Colab 환경에서 Kaggle 환경으로 실습환경 이관. Kaggle은 여전히 python 버전이 3.11임.\n* 기존 Colab의 디렉토리 구조는 /content 디렉토리를 기반으로 실습코드 수행됨. Kaggle에서는 /kaggle/working이며 자동으로 현재디렉토리(.)로 실습 코드를 변경함\n* 2025년 8월 25일 download.openmmlab.com 사이트의 ssl 이슈로 pip install 에 --trusted-host 옵션 및 wget에 --no-check-certificate 옵션 추가","metadata":{"id":"c7XRP9bwSfJu"}},{"cell_type":"markdown","source":"#### pytorch, torchvision 다운그레이드","metadata":{"id":"BSjXKstzYkSJ"}},{"cell_type":"code","source":"import torch\nprint(torch.__version__)","metadata":{"id":"DKzS19hadG4_","executionInfo":{"status":"ok","timestamp":1671537019026,"user_tz":-540,"elapsed":2406,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"0155c2e7-add1-4804-dcfb-c244667d1ef5","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pytorch 버전을 2.0으로 downgrade\n!pip install torch==2.0.0 torchvision==0.15.1 --index-url https://download.pytorch.org/whl/cu118","metadata":{"id":"xJkO1dPo1-2b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### mmcv-full 설치\n* mmcv-full은 1.7.2 버전으로 설치. ssl 인증 이슈로 --trusted-host 옵션 추가","metadata":{"id":"-0QBU3E7YpWf"}},{"cell_type":"code","source":"!pip install mmcv-full --trusted-host download.openmmlab.com -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.0/index.html","metadata":{"id":"eUGm5N_lcc_W","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### MMDetection 2.x 버전 설치\n* 2023년 4월 6일 기준으로 mmdetection이 3.0으로 upgrade됨. 실습 코드는 mmdetection 2.x 기준임.\n* mmdetection 2.x branch의 소스코드 기반으로 mmdetection 설치 필요.","metadata":{}},{"cell_type":"code","source":"# 2023년 4월 6일 기준으로 mmdetection이 3.0으로 upgrade됨. 실습 코드는 mmdetection 2.x 기준임.\n# mmdetection 2.x branch의 소스코드 기반으로 mmdetection 설치 필요.\n!git clone --branch 2.x https://github.com/open-mmlab/mmdetection.git\n!cd mmdetection; python setup.py install","metadata":{"id":"cThVMqmfcezJ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### mmdetection 2.x 버전에서 numpy 호환성 이슈로 numpy downgrade\n* 반드시 numpy downgrade를 mmcv 설치 후에 실행할것.","metadata":{}},{"cell_type":"code","source":"### 반드시 numpy downgrade를 mmcv 설치 후에 실행할것.\n!pip install numpy==1.23","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### mmcv와 mmdetection이 제대로 설치되었는지 확인 ","metadata":{}},{"cell_type":"code","source":"# 아래를 수행하기 전에 kernel을 restart 해야 함.\nfrom mmdet.apis import init_detector, inference_detector\nimport mmcv","metadata":{"id":"KbAnpNg9Q8dG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537144839,"user_tz":-540,"elapsed":6316,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"a7b4ed5a-c75d-48a5-d09f-ddf6ab511e27","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### PASCAL VOC 2007 데이터 세트 다운로드\n* PASCAL VOC 데이터 세트가 공식 사이트, Mirror 사이트에서 모두 다운로드 되지 않으므로 아래에서 다운로드\n* https://drive.google.com/file/d/1cx5yb_eNwQ3XVLv5W1kkiCDepL3G7nkL/view?usp=sharing","metadata":{"id":"tjsrX8SFSnK7"}},{"cell_type":"code","source":"#PASCAL VOC 데이터 세트가 공식 사이트, Mirror 사이트에서 모두 다운로드 되지 않으므로 아래에서 다운로드\n!pip install gdown\n!gdown --fuzzy https://drive.google.com/file/d/1cx5yb_eNwQ3XVLv5W1kkiCDepL3G7nkL/view?usp=sharing\n!tar -xvf VOCtrainval_06-Nov-2007.tar > /dev/null 2>&1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pjreddie.com 사이트에서 더 이상 다운로드 되지 않음\n# !wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n# !tar -xvf VOCtrainval_06-Nov-2007.tar > /dev/null 2>&1","metadata":{"id":"rKHMaXju2EOE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537186369,"user_tz":-540,"elapsed":25015,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"3cb8f9c1-d1f7-48a7-b89e-9a8b09c3fbdb","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### MMDetection은 Mask RCNN을 학습하기 위해서는 COCO 포맷을 가장 선호\n* CocoDataset으로 지정해야만, evaluation 시 mask evaluation 정보 제공.(2021년 6월 기준) https://mmdetection.readthedocs.io/en/latest/tutorials/customize_dataset.html\n* Pascal voc 포맷을 Coco 포맷으로 변환할 수 있는 유틸리티를 활용하여 데이터 변환\nhttps://github.com/ISSResearch/Dataset-Converters\n* Dataset converter 패키지가 opencv를 3.4로 downgrade함에 유의\n* 강의 영상은 colab 기준. /content 디렉토리를 kaggle 기준으로 현재 디렉토리 /kaggle/working 로 전환","metadata":{"id":"-rvSmtd4SyIW"}},{"cell_type":"code","source":"import cv2\nprint(cv2.__version__)","metadata":{"id":"KJg7Mj7rYIlG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537260152,"user_tz":-540,"elapsed":406,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"b27b8151-e6f4-4e5c-cb5b-c6bc9a15d287","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/ISSResearch/Dataset-Converters.git","metadata":{"id":"4KQXbBV7wBjO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537262836,"user_tz":-540,"elapsed":1096,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"8d903a2f-97f5-4d66-dd37-596987d97d41","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cd Dataset-Converters; pip install -r requirements.txt","metadata":{"id":"rk8lq3PNjsig","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537277925,"user_tz":-540,"elapsed":13858,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"ad5bbe53-b0e8-447d-fbe9-6d84995b7cd7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir /kaggle/working/coco_output\n!cd Dataset-Converters;python convert.py --input-folder /kaggle/working/VOCdevkit/VOC2007 --output-folder /kaggle/working/coco_output \\\n                  --input-format VOCSEGM --output-format COCO --copy","metadata":{"id":"2aDFbNkjWQmh","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 아래와 같이 opencv 버전을 원복 재 설치할 필요 없음. 2025.08.26\n# !pip install opencv-python==4.1.2.30","metadata":{"id":"h7xdA8F_ZT3E","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1671537292233,"user_tz":-540,"elapsed":6713,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"800c58e3-9ba5-4034-be35-c0de578fbf2f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 생성된 Coco Annotation json 파일 살펴 보기","metadata":{"id":"Wh0LZFGwbB_5"}},{"cell_type":"code","source":"!sudo apt-get install jq","metadata":{"id":"TROJ8YQuaOTp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537300124,"user_tz":-540,"elapsed":7896,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"63d4ecc0-7818-44ec-b927-b4f90fde8115","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!jq . /kaggle/working/coco_output/annotations/train.json > output.json","metadata":{"id":"uX7X1MoSaOXM","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!head -200 output.json","metadata":{"id":"OhzkICHXaOaa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537300724,"user_tz":-540,"elapsed":9,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"ad18bdb4-972a-4963-bccf-36722af89fb5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tail -200 output.json","metadata":{"id":"Jg1nUKl6aOdC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537300724,"user_tz":-540,"elapsed":5,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"dcb0b3fd-3236-4255-f888-386cd08e4dc4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!grep -n 'annotations' output.json","metadata":{"id":"_zTNFwsSakv6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537301194,"user_tz":-540,"elapsed":472,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"3b713a71-8550-481e-d3f6-b943f2b8db43","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!head -1600 output.json | tail -400","metadata":{"id":"8hp4Ufz7apHW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537301194,"user_tz":-540,"elapsed":6,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"72aeecda-b52e-4690-c74e-1188a326da1c","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Pretrained 모델 다운로드 및 Config, Dataset설정.\n* Colab의 디렉토리 구조는 /content 디렉토리를 기반으로 실습코드 수행됨. Kaggle에서는 /kaggle/working이며 자동으로 현재디렉토리(.)로 실습 코드를 변경함\n* download.openmmlab.com 사이트의 ssl 이슈로 wget에 --no-check-certificate 옵션 추가","metadata":{"id":"dBldbcCSbUj3"}},{"cell_type":"code","source":"# pretrained weight 모델을 다운로드 받기 위해서 mmdetection/checkpoints 디렉토리를 만듬.\n!cd mmdetection; mkdir checkpoints","metadata":{"id":"0bEeppPQG_sr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget --no-check-certificate -O /kaggle/working/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth http://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r101_fpn_1x_coco/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth","metadata":{"id":"KwcBRmjdQDLQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537305950,"user_tz":-540,"elapsed":4758,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"4c748a59-fb87-4e5e-b152-62c56676259b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lia /kaggle/working/mmdetection/checkpoints","metadata":{"id":"Ifz2eS2lBqMJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537306906,"user_tz":-540,"elapsed":958,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"fa914a85-4713-4426-970f-881d937587f7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# config 파일을 설정하고, 다운로드 받은 pretrained 모델을 checkpoint로 설정.\nconfig_file = '/kaggle/working/mmdetection/configs/mask_rcnn/mask_rcnn_r101_fpn_1x_coco.py'\ncheckpoint_file = '/kaggle/working/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth'","metadata":{"id":"3uTqmO5EQDOC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from mmdet.datasets.builder import DATASETS\nfrom mmdet.datasets.coco import CocoDataset\n\n@DATASETS.register_module(force=True)\nclass VOCDataset(CocoDataset):\n  CLASSES = ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',\n               'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n               'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train',\n               'tvmonitor')","metadata":{"id":"WKPZrx6HQDQe","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from mmcv import Config\n\ncfg = Config.fromfile(config_file)\nprint(cfg.pretty_text)","metadata":{"id":"VrPweafhQDTd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671537306907,"user_tz":-540,"elapsed":5,"user":{"displayName":"권철민","userId":"03917677622451543916"}},"outputId":"bf55f48a-c30b-4a4f-cf5f-3fe10f3d246a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from mmdet.apis import set_random_seed\n\n# dataset에 대한 환경 파라미터 수정.\ncfg.dataset_type = 'VOCDataset'\ncfg.data_root = '/kaggle/working/coco_output/'\n\n# train, val, test dataset에 대한 type, data_root, ann_file, img_prefix 환경 파라미터 수정.\ncfg.data.train.type = 'VOCDataset'\ncfg.data.train.data_root = '/kaggle/working/coco_output/'\ncfg.data.train.ann_file = 'annotations/train.json'\ncfg.data.train.img_prefix = 'train'\n\ncfg.data.val.type = 'VOCDataset'\ncfg.data.val.data_root = '/kaggle/working/coco_output/'\ncfg.data.val.ann_file = 'annotations/val.json'\ncfg.data.val.img_prefix = 'val'\n\n\n# class의 갯수를 pascal voc로 설정.  수정.\ncfg.model.roi_head.bbox_head.num_classes = 20\ncfg.model.roi_head.mask_head.num_classes = 20\n\n# pretrained 모델\ncfg.load_from = '/kaggle/working/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth'\n\n# 학습 weight 파일로 로그를 저장하기 위한 디렉토리 설정.\ncfg.work_dir = './tutorial_exps'\n\n# 학습율 변경 환경 파라미터 설정.\ncfg.optimizer.lr = 0.02 / 8\ncfg.lr_config.warmup = None\ncfg.log_config.interval = 10\n\n# CocoDataset의 경우 metric을 bbox로 설정해야 함.(mAP아님. bbox로 설정하면 mAP를 iou threshold를 0.5 ~ 0.95까지 변경하면서 측정)\ncfg.evaluation.metric = ['bbox', 'segm']\ncfg.evaluation.interval = 12\ncfg.checkpoint_config.interval = 12\n\n# 두번 config를 로드하면 lr_config의 policy가 사라지는 오류로 인하여 설정.\ncfg.lr_config.policy='step'\n# Set seed thus the results are more reproducible\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\n\n# ConfigDict' object has no attribute 'device 오류 발생시 반드시 설정 필요. https://github.com/open-mmlab/mmdetection/issues/7901\ncfg.device='cuda'","metadata":{"id":"udEntY3Gj8VP","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(cfg.pretty_text)","metadata":{"id":"KXbuUXRyj8Yt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\n\n# train용 Dataset 생성.\ndatasets = [build_dataset(cfg.data.train)]","metadata":{"id":"wd2Bik8Fj8cD","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\nprint(model.CLASSES)","metadata":{"id":"u7YF5h7Hj8ft","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os.path as osp\nmmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n# epochs는 config의 runner 파라미터로 지정됨. 기본 12회\ntrain_detector(model, datasets, cfg, distributed=False, validate=True)","metadata":{"id":"VgxxeD9Jj8ia","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 학습된 모델을 이용하여 단일 이미지와 Video Inference 수행.","metadata":{"id":"IEm1hGrzdV0o"}},{"cell_type":"code","source":"from mmdet.apis import show_result_pyplot\n\ncheckpoint_file = '/kaggle/working/tutorial_exps/epoch_12.pth'\n\n# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용.\nmodel_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')\n# BGR Image 사용\nimg = cv2.imread('/kaggle/working/VOCdevkit/VOC2007/JPEGImages/000007.jpg')\n#model_ckpt.cfg = cfg\n\nresult = inference_detector(model_ckpt, img)\nshow_result_pyplot(model_ckpt, img, result, score_thr=0.5)","metadata":{"id":"IS78SaUh5giE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir /kaggle/working/data\n!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg","metadata":{"id":"-zQONtMS6bRn","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv2.imread('/kaggle/working/data/beatles01.jpg')\n#model_ckpt.cfg = cfg\n\nresult = inference_detector(model_ckpt, img)\nshow_result_pyplot(model_ckpt, img, result, score_thr=0.5)","metadata":{"id":"nEAdcLjA6bgt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Video Inference 수행\n* get_detected_img()함수를 이용하여 Inference 수행.","metadata":{"id":"jcX5PLi37cy2"}},{"cell_type":"code","source":"!wget -O /kaggle/working/data/London_Street.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/London_Street.mp4?raw=true","metadata":{"id":"4UKrr1Hfj8nx","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nlabels_to_names_seq =  {0:'aeroplane', 1:'bicycle', 2:'bird', 3:'boat', 4:'bottle', 5:'bus', 6:'car',\n               7:'cat', 8:'chair', 9:'cow', 10:'diningtable', 11:'dog', 12:'horse',\n               13:'motorbike', 14:'person', 15:'pottedplant', 16:'sheep', 17:'sofa', 18:'train',\n               19:'tvmonitor'}\n\ncolors = list(\n    [[0, 255, 0],\n     [0, 0, 255],\n     [255, 0, 0],\n     [0, 255, 255],\n     [255, 255, 0],\n     [255, 0, 255],\n     [80, 70, 180],\n     [250, 80, 190],\n     [245, 145, 50],\n     [70, 150, 250]] )","metadata":{"id":"OuOty1BK7da2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model과 원본 이미지 array, filtering할 기준 class confidence score를 인자로 가지는 inference 시각화용 함수 생성.\n# 이미 inference 시 mask boolean값이 들어오므로 mask_threshold 값을 필요하지 않음.\ndef get_detected_img(model, img_array,  score_threshold=0.3, is_print=True):\n  # 인자로 들어온 image_array를 복사.\n  draw_img = img_array.copy()\n  bbox_color=(0, 255, 0)\n  text_color=(0, 0, 255)\n\n  # model과 image array를 입력 인자로 inference detection 수행하고 결과를 results로 받음.\n  # results는 80개의 2차원 array(shape=(오브젝트갯수, 5))를 가지는 list.\n  results = inference_detector(model, img_array)\n  bbox_results = results[0]\n  seg_results = results[1]\n\n  # 80개의 array원소를 가지는 results 리스트를 loop를 돌면서 개별 2차원 array들을 추출하고 이를 기반으로 이미지 시각화\n  # results 리스트의 위치 index가 바로 COCO 매핑된 Class id. 여기서는 result_ind가 class id\n  # 개별 2차원 array에 오브젝트별 좌표와 class confidence score 값을 가짐.\n  for result_ind, bbox_result in enumerate(bbox_results):\n    # 개별 2차원 array의 row size가 0 이면 해당 Class id로 값이 없으므로 다음 loop로 진행.\n    if len(bbox_result) == 0:\n      continue\n\n    mask_array_list = seg_results[result_ind]\n\n    # 해당 클래스 별로 Detect된 여러개의 오브젝트 정보가 2차원 array에 담겨 있으며, 이 2차원 array를 row수만큼 iteration해서 개별 오브젝트의 좌표값 추출.\n    for i in range(len(bbox_result)):\n      # 좌상단, 우하단 좌표 추출.\n      if bbox_result[i, 4] > score_threshold:\n        left = int(bbox_result[i, 0])\n        top = int(bbox_result[i, 1])\n        right = int(bbox_result[i, 2])\n        bottom = int(bbox_result[i, 3])\n        caption = \"{}: {:.4f}\".format(labels_to_names_seq[result_ind], bbox_result[i, 4])\n        cv2.rectangle(draw_img, (left, top), (right, bottom), color=bbox_color, thickness=2)\n        cv2.putText(draw_img, caption, (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.37, text_color, 1)\n        # masking 시각화 적용. class_mask_array는 image 크기 shape의  True/False값을 가지는 2차원 array\n        class_mask_array = mask_array_list[i]\n        # 원본 image array에서 mask가 True인 영역만 별도 추출.\n        masked_roi = draw_img[class_mask_array]\n        #color를 임의 지정\n        #color_index = np.random.randint(0, len(colors)-1)\n        # color를 class별로 지정\n        color_index = result_ind % len(colors)\n        color = colors[color_index]\n        # apply_mask()함수를 적용시 수행 시간이 상대적으로 오래 걸림.\n        #draw_img = apply_mask(draw_img, class_mask_array, color, alpha=0.4)\n        # 원본 이미지의 masking 될 영역에 mask를 특정 투명 컬러로 적용\n        draw_img[class_mask_array] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.6 * masked_roi).astype(np.uint8)\n        if is_print:\n          print(caption)\n\n  return draw_img\n","metadata":{"id":"qgNcOvwm7QbQ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\ndef do_detected_video(model, input_path, output_path, score_threshold, do_print=True):\n\n    cap = cv2.VideoCapture(input_path)\n\n    codec = cv2.VideoWriter_fourcc(*'XVID')\n\n    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n\n    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n\n    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    print('총 Frame 갯수:', frame_cnt)\n    btime = time.time()\n    while True:\n        hasFrame, img_frame = cap.read()\n        if not hasFrame:\n            print('더 이상 처리할 frame이 없습니다.')\n            break\n        stime = time.time()\n        img_frame = get_detected_img(model, img_frame,  score_threshold=score_threshold,is_print=False)\n        if do_print:\n          print('frame별 detection 수행 시간:', round(time.time() - stime, 4))\n        vid_writer.write(img_frame)\n    # end of while loop\n\n    vid_writer.release()\n    cap.release()\n\n    print('최종 detection 완료 수행 시간:', round(time.time() - btime, 4))","metadata":{"id":"rOnTeurI78Ny","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"do_detected_video(model_ckpt, '/kaggle/working/data/London_Street.mp4', '/kaggle/working/data/London_Street_out01.mp4', score_threshold=0.4, do_print=True)","metadata":{"id":"g3vr964M8EGl","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"UPJra-WN8IyA","trusted":true},"outputs":[],"execution_count":null}]}
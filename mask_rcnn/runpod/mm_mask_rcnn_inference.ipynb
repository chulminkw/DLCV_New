{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlIOlLLLjAP7"
   },
   "outputs": [],
   "source": [
    "### 모듈 import\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_dDdanyVrJ2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHm73mVCQmpc"
   },
   "source": [
    "### MS-COCO 데이터 기반으로 Mask RCNN Pretrained 모델을 활용하여 Inference 수행\n",
    "* Mask RCNN Pretrained 모델 다운로드\n",
    "* Mask RCNN용 Config 파일 설정.  \n",
    "* Inference 용 모델을 생성하고, Inference 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gs162gTppmTh"
   },
   "outputs": [],
   "source": [
    "# pretrained weight 모델을 다운로드 받기 위해서 mmdetection/checkpoints 디렉토리를 만듬.\n",
    "!cd mmdetection; mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvBLA2ecqJsV"
   },
   "outputs": [],
   "source": [
    "!wget -O /content/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth http://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r101_fpn_1x_coco/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbETJ0zYh_bf"
   },
   "outputs": [],
   "source": [
    "!ls -lia /content/mmdetection/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHyGQYXpoM_u"
   },
   "outputs": [],
   "source": [
    "# config 파일을 설정하고, 다운로드 받은 pretrained 모델을 checkpoint로 설정.\n",
    "config_file = '/content/mmdetection/configs/mask_rcnn/mask_rcnn_r101_fpn_1x_coco.py'\n",
    "checkpoint_file = '/content/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUgqp_sOpPKN"
   },
   "outputs": [],
   "source": [
    "# config 파일과 pretrained 모델을 기반으로 Detector 모델을 생성.\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DwPX9OslRgc"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img = '/content/mmdetection/demo/demo.jpg'\n",
    "\n",
    "img_arr  = cv2.imread(img)\n",
    "img_arr_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img_arr_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1U7BfoXrpR4l"
   },
   "outputs": [],
   "source": [
    "img_path = '/content/mmdetection/demo/demo.jpg'\n",
    "# inference_detector의 인자로 string(file경로), ndarray가 단일 또는 list형태로 입력 될 수 있음.\n",
    "results = inference_detector(model, img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAdCpXVXQC3S"
   },
   "outputs": [],
   "source": [
    "from mmdet.apis import show_result_pyplot\n",
    "# inference 된 결과를 원본 이미지에 적용하여 새로운 image로 생성(bbox 처리된 image)\n",
    "# Default로 score threshold가 0.3 이상인 Object들만 시각화 적용. show_result_pyplot은 model.show_result()를 호출.\n",
    "show_result_pyplot(model, img_arr, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXcqjkK2jdHA"
   },
   "source": [
    "### Inference 결과로 반환되는 results 값 살펴 보기\n",
    "* inference_detector(model, img_path)의 결과로 반환되는 값은 instance segmentation 일 경우 Object Detection 결과에 추가되어 segmentation masking 정보도 함께 반환됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkWvvhR6qvcZ"
   },
   "outputs": [],
   "source": [
    "type(results), len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9pNu_6OfenS"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGjvF2pNQVJI"
   },
   "outputs": [],
   "source": [
    "print(type(results[0]), len(results[0]), type(results[1]), len(results[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdRdB45NQqG1"
   },
   "outputs": [],
   "source": [
    "'''results[0]는 list형으로 coco class의  0부터 79까지 class_id별로 80개의 array를 가짐.\n",
    "개별 array들은 각 클래스별로 5개의 값(좌표값과 class별로 confidence)을 가짐. 개별 class별로 여러개의 좌표를 가지면 여러개의 array가 생성됨.\n",
    "좌표는 좌상단(xmin, ymin), 우하단(xmax, ymax) 기준.\n",
    "개별 array의 shape는 (Detection된 object들의 수, 5(좌표와 confidence)) 임\n",
    "'''\n",
    "print(type(results[0][0]), results[0][0].shape, results[0][1].shape, results[0][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ou9DI1ayQIvr"
   },
   "outputs": [],
   "source": [
    "# results[1]은 masking 정보를 가짐. coco class의  0부터 79까지 class_id 별로 80개의 list를 가짐. 개별 list는 개별 object의 mask 정보를 내부 원소로 가짐.\n",
    "# 개별 object의 mask 정보는 2차원 array로서 image의 height x width 형태를 가짐.\n",
    "print('results[1]의 첫번째 원소의 type과 size:', type(results[1][0]), len(results[1][0]), '두번째 원소 사이즈:', len(results[1][1]), '세번째 원소 사이즈:', len(results[1][2]))\n",
    "print('results[1]의 첫번째 원소 list의 첫번째 원소 type과 shape:', type(results[1][0][0]), results[1][0][0].shape)\n",
    "#print('results[1]의 두번째 원소 list의 첫번째 원소 type과 shape:', type(results[1][1][0]))\n",
    "print('results[1]의 세번째 원소 list의 첫번째/두번째/세번째 원소 shape:', results[1][2][0].shape, results[1][2][1].shape, results[1][2][2].shape)\n",
    "print('image shape:', img_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HM7y-_dS1Yq"
   },
   "outputs": [],
   "source": [
    "mask_imsi = results[1][0][0]\n",
    "print(mask_imsi)\n",
    "print(mask_imsi[mask_imsi > 0], mask_imsi[mask_imsi == 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sN-7fTm8k4jj"
   },
   "outputs": [],
   "source": [
    "mask_imsi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LL17XN52k9ar"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mask_index = np.where(mask_imsi > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6vBuTi6laQX"
   },
   "outputs": [],
   "source": [
    "np.array(mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R59_Vi9rlqXm"
   },
   "outputs": [],
   "source": [
    "img_arr_rgb_copy = img_arr_rgb.copy()\n",
    "img_arr_rgb_copy[mask_index[0], mask_index[1], :] =0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIwwL6-2l9US"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img_arr_rgb_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bipE2MKLOa_b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "  for c in range(3):\n",
    "    # mask값이 1일 경우는 원본 pixel값에 컬러 segmentation을 적용하고, 그렇지 않을 경우 원본 pixel값을 그대로 유지.\n",
    "    image[:, :, c] = np.where(mask == 1,\n",
    "                              image[:, :, c] *\n",
    "                              (1 - alpha) + alpha * color[c] * 255,\n",
    "                              image[:, :, c])\n",
    "  return image\n",
    "\n",
    "\n",
    "draw_img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "masked_image = apply_mask(draw_img, results[1][2][0], (0, 255, 0), alpha=0.6)\n",
    "plt.figure(figsize=(12, 14))\n",
    "plt.imshow(masked_image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trgaz_nOrfl2"
   },
   "source": [
    "### Video Detection 실행\n",
    "* mmdetection의 model.show_result()를 실행하여 frame별로 object detect 된 결과를 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJDIEqGwq9wu"
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "688qOoVMKH9u"
   },
   "outputs": [],
   "source": [
    "!wget -O /content/data/John_Wick_small.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/John_Wick_small.mp4?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsM3nWsBKIBe"
   },
   "outputs": [],
   "source": [
    "# https://github.com/open-mmlab/mmdetection/blob/master/demo/video_demo.py 대로 video detection 수행.\n",
    "import cv2\n",
    "\n",
    "video_reader = mmcv.VideoReader('/content/data/John_Wick_small.mp4')\n",
    "video_writer = None\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter('/content/data/John_Wick_small_out1.mp4', fourcc, video_reader.fps,(video_reader.width, video_reader.height))\n",
    "\n",
    "for frame in mmcv.track_iter_progress(video_reader):\n",
    "  result = inference_detector(model, frame)\n",
    "  frame = model.show_result(frame, result, score_thr=0.4)\n",
    "\n",
    "  video_writer.write(frame)\n",
    "\n",
    "if video_writer:\n",
    "        video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZexB8Dvr1kW"
   },
   "source": [
    "### segmentation 시각화 함수 직접 작성 후 단일 이미지와 Video inference 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohYU8ottv5Zu"
   },
   "outputs": [],
   "source": [
    "# 0부터 순차적으로 클래스 매핑된 label 적용.\n",
    "labels_to_names_seq = {0:'person',1:'bicycle',2:'car',3:'motorbike',4:'aeroplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',10:'fire hydrant',\n",
    "                        11:'stop sign',12:'parking meter',13:'bench',14:'bird',15:'cat',16:'dog',17:'horse',18:'sheep',19:'cow',20:'elephant',\n",
    "                        21:'bear',22:'zebra',23:'giraffe',24:'backpack',25:'umbrella',26:'handbag',27:'tie',28:'suitcase',29:'frisbee',30:'skis',\n",
    "                        31:'snowboard',32:'sports ball',33:'kite',34:'baseball bat',35:'baseball glove',36:'skateboard',37:'surfboard',38:'tennis racket',39:'bottle',40:'wine glass',\n",
    "                        41:'cup',42:'fork',43:'knife',44:'spoon',45:'bowl',46:'banana',47:'apple',48:'sandwich',49:'orange',50:'broccoli',\n",
    "                        51:'carrot',52:'hot dog',53:'pizza',54:'donut',55:'cake',56:'chair',57:'sofa',58:'pottedplant',59:'bed',60:'diningtable',\n",
    "                        61:'toilet',62:'tvmonitor',63:'laptop',64:'mouse',65:'remote',66:'keyboard',67:'cell phone',68:'microwave',69:'oven',70:'toaster',\n",
    "                        71:'sink',72:'refrigerator',73:'book',74:'clock',75:'vase',76:'scissors',77:'teddy bear',78:'hair drier',79:'toothbrush' }\n",
    "\n",
    "colors = list(\n",
    "    [[0, 255, 0],\n",
    "     [0, 0, 255],\n",
    "     [255, 0, 0],\n",
    "     [0, 255, 255],\n",
    "     [255, 255, 0],\n",
    "     [255, 0, 255],\n",
    "     [80, 70, 180],\n",
    "     [250, 80, 190],\n",
    "     [245, 145, 50],\n",
    "     [70, 150, 250]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VlaaDH6E2Uel"
   },
   "outputs": [],
   "source": [
    "#mask threshold값은 mask_thr_binary=0.5 로 지정되어 있음.\n",
    "print(model.cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyzT-CAiv5c7"
   },
   "outputs": [],
   "source": [
    "# model과 원본 이미지 array, filtering할 기준 class confidence score를 인자로 가지는 inference 시각화용 함수 생성.\n",
    "# 이미 inference 시 mask boolean값이 들어오므로 mask_threshold 값을 필요하지 않음.\n",
    "def get_detected_img(model, img_array,  score_threshold=0.3, is_print=True):\n",
    "  # 인자로 들어온 image_array를 복사.\n",
    "  draw_img = img_array.copy()\n",
    "  bbox_color=(0, 255, 0)\n",
    "  text_color=(0, 0, 255)\n",
    "\n",
    "  # model과 image array를 입력 인자로 inference detection 수행하고 결과를 results로 받음.\n",
    "  # results는 80개의 2차원 array(shape=(오브젝트갯수, 5))를 가지는 list.\n",
    "  results = inference_detector(model, img_array)\n",
    "  bbox_results = results[0]\n",
    "  seg_results = results[1]\n",
    "\n",
    "  # 80개의 array원소를 가지는 results 리스트를 loop를 돌면서 개별 2차원 array들을 추출하고 이를 기반으로 이미지 시각화\n",
    "  # results 리스트의 위치 index가 바로 COCO 매핑된 Class id. 여기서는 result_ind가 class id\n",
    "  # 개별 2차원 array에 오브젝트별 좌표와 class confidence score 값을 가짐.\n",
    "  for result_ind, bbox_result in enumerate(bbox_results):\n",
    "    # 개별 2차원 array의 row size가 0 이면 해당 Class id로 값이 없으므로 다음 loop로 진행.\n",
    "    if len(bbox_result) == 0:\n",
    "      continue\n",
    "\n",
    "    mask_array_list = seg_results[result_ind]\n",
    "\n",
    "    # 해당 클래스 별로 Detect된 여러개의 오브젝트 정보가 2차원 array에 담겨 있으며, 이 2차원 array를 row수만큼 iteration해서 개별 오브젝트의 좌표값 추출.\n",
    "    for i in range(len(bbox_result)):\n",
    "      # 좌상단, 우하단 좌표 추출.\n",
    "      if bbox_result[i, 4] > score_threshold:\n",
    "        left = int(bbox_result[i, 0])\n",
    "        top = int(bbox_result[i, 1])\n",
    "        right = int(bbox_result[i, 2])\n",
    "        bottom = int(bbox_result[i, 3])\n",
    "        caption = \"{}: {:.4f}\".format(labels_to_names_seq[result_ind], bbox_result[i, 4])\n",
    "        cv2.rectangle(draw_img, (left, top), (right, bottom), color=bbox_color, thickness=2)\n",
    "        cv2.putText(draw_img, caption, (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.37, text_color, 1)\n",
    "        # masking 시각화 적용. class_mask_array는 image 크기 shape의  True/False값을 가지는 2차원 array\n",
    "        class_mask_array = mask_array_list[i]\n",
    "        # 원본 image array에서 mask가 True인 영역만 별도 추출.\n",
    "        masked_roi = draw_img[class_mask_array]\n",
    "        #color를 임의 지정\n",
    "        color_index = np.random.randint(0, len(colors)-1)\n",
    "        # color를 class별로 지정\n",
    "        #color_index = result_ind % len(colors)\n",
    "        color = colors[color_index]\n",
    "        # apply_mask()함수를 적용시 수행 시간이 상대적으로 오래 걸림.\n",
    "        #draw_img = apply_mask(draw_img, class_mask_array, color, alpha=0.4)\n",
    "        # 원본 이미지의 masking 될 영역에 mask를 특정 투명 컬러로 적용\n",
    "        draw_img[class_mask_array] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.6 * masked_roi).astype(np.uint8)\n",
    "        if is_print:\n",
    "          print(caption)\n",
    "\n",
    "  return draw_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiK0Z8sqGi7l"
   },
   "outputs": [],
   "source": [
    "img_arr = cv2.imread('/content/mmdetection/demo/demo.jpg')\n",
    "mask_array = results[1][2][0]\n",
    "print('image array shape:', img_arr.shape)\n",
    "print('mask array shape:', mask_array.shape)\n",
    "print('mask true array shape:', mask_array[mask_array].shape)\n",
    "print('masked array shape:', img_arr[results[1][2][0]].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TTcVFEu43pQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_arr = cv2.imread('/content/mmdetection/demo/demo.jpg')\n",
    "detected_img = get_detected_img(model, img_arr,  score_threshold=0.3, is_print=True)\n",
    "# detect 입력된 이미지는 bgr임. 이를 최종 출력시 rgb로 변환\n",
    "detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(detected_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kh54JphBA_Fa"
   },
   "outputs": [],
   "source": [
    "!mkdir /content/data\n",
    "!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmm3ySEW430t"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_arr = cv2.imread('/content/data/beatles01.jpg')\n",
    "detected_img = get_detected_img(model, img_arr,  score_threshold=0.3, is_print=True)\n",
    "# detect 입력된 이미지는 bgr임. 이를 최종 출력시 rgb로 변환\n",
    "detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(detected_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7kiQhPu4394"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def do_detected_video(model, input_path, output_path, score_threshold, do_print=True):\n",
    "\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n",
    "\n",
    "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('총 Frame 갯수:', frame_cnt)\n",
    "    btime = time.time()\n",
    "    while True:\n",
    "        hasFrame, img_frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            print('더 이상 처리할 frame이 없습니다.')\n",
    "            break\n",
    "        stime = time.time()\n",
    "        img_frame = get_detected_img(model, img_frame,  score_threshold=score_threshold,is_print=False)\n",
    "        if do_print:\n",
    "          print('frame별 detection 수행 시간:', round(time.time() - stime, 4))\n",
    "        vid_writer.write(img_frame)\n",
    "    # end of while loop\n",
    "\n",
    "    vid_writer.release()\n",
    "    cap.release()\n",
    "\n",
    "    print('최종 detection 완료 수행 시간:', round(time.time() - btime, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mznJS9NKKr03"
   },
   "outputs": [],
   "source": [
    "do_detected_video(model, '/content/data/John_Wick_small.mp4', '/content/data/John_Wick_small_out2.mp4', score_threshold=0.4, do_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykNwhsR4Kr4h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWzbe1ar1Plo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOjaYqQ0KqYyTzgxVkyQBSn",
   "provenance": [
    {
     "file_id": "1wTFFEFF-nikaOONcOC-i6Ck_f9Ozn7dB",
     "timestamp": 1623381607498
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

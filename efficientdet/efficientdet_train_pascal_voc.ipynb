{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITh-aCvnbuVC"
      },
      "source": [
        "### automl efficientdet 다운로드 및 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvrAFJSvbeMy"
      },
      "source": [
        "!git clone --depth 1 https://github.com/google/automl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ZHXPucQ8zr"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y03QuHJbe9g"
      },
      "source": [
        "!cd /content/automl/efficientdet; pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ura5hJVWbnra"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYRi19QLb8aq"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "sys.path.append('/content/automl/efficientdet')\n",
        "\n",
        "import hparams_config\n",
        "from tf2 import anchors\n",
        "from model_inspect import ModelInspector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzE89QkVcJfe"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9qy48rsbzK-"
      },
      "source": [
        "###  PASCAL V0C 2007 데이터 세트 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URN9r_u_bfM1"
      },
      "source": [
        "!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
        "!tar -xvf VOCtrainval_06-Nov-2007.tar > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZyP9sthdX5n"
      },
      "source": [
        "!ls -lia /content/VOCdevkit/VOC2007/Annotations/*.xml| wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrCUa5avdUAk"
      },
      "source": [
        "### 학습 데이터와 검증 데이터를 tfrecord 형태로 변환\n",
        "* create_pascal_tfrecord.py를 이용하여 XML 포맷의 Annotation을 tfrecord로 변환.\n",
        "* create_pascal_tfrecord.py 는 ImageSet 디렉토리에 위치한 train.txt를 읽어서 해당 xml과 image를 train용 tfrecord로 변환. val.txt를 읽어서 valid용 tfrecord로 변환.\n",
        "* train과 val용 각각 약 2500여개의 image/xml를 100개씩 하나의 tfrecord로 생성."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvQEkxjNb5DN"
      },
      "source": [
        "!mkdir -p /content/tfrecord/train\n",
        "!mkdir -p /content/tfrecord/val\n",
        "\n",
        "# --output_path=/content/tfrecord/train/pascal에서 directory는 /content/tfrecord/train/ 까지, 뒤의 pascal을 tfrecord파일의 prefix임..\n",
        "!cd /content/automl/efficientdet; PYTHONPATH=\"/content/automl/efficientdet:$PYTHONPATH\" python dataset/create_pascal_tfrecord.py  \\\n",
        "    --data_dir=/content/VOCdevkit --year=VOC2007 --set=train --output_path=/content/tfrecord/train/pascal\n",
        "\n",
        "!cd /content/automl/efficientdet; PYTHONPATH=\"/content/automl/efficientdet:$PYTHONPATH\" python dataset/create_pascal_tfrecord.py  \\\n",
        "    --data_dir=/content/VOCdevkit --year=VOC2007 --set=val --output_path=/content/tfrecord/val/pascal\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92TkqIYz_xk"
      },
      "source": [
        "### Train용 config 설정.\n",
        "* 학습을 위한 다양한 설정을 config로 저장. model은 efficientdet-d0 로 적용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFRHuC7EpDns"
      },
      "source": [
        "# epochs시마다 학습된 weight파일을 저장한 디렉토리 Google drive로 설정.\n",
        "# Google Drive 접근을 위한 Mount 적용.\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# soft link로 Google Drive Directory 연결.\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive\n",
        "!mkdir -p /mydrive/model_trained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjZeIaiH0UW2"
      },
      "source": [
        "config = hparams_config.get_detection_config('efficientdet-d0')\n",
        "print(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5bklgGdf0Q_"
      },
      "source": [
        "class TRAIN_CFG:\n",
        "  model_name = 'efficientdet-d0' # efficientdet 모델명\n",
        "  strategy = '' # tpu, 여러개의 GPU들, 단일 GPU 일때 학습 strategy 설정.\n",
        "  model_dir = '/mydrive/model_trained' # 학습된 모델이 저장될 위치\n",
        "  pretrained_ckpt = '/content/efficientdet-d0'\n",
        "  hparams = 'num_classes=20,moving_average_decay=0,mixed_precision=true'\n",
        "  use_xla = False\n",
        "  use_fake_data = False\n",
        "  batch_size = 8\n",
        "  eval_samples = 5000 # evaluation image 데이터 갯수\n",
        "  steps_per_execution = 1 # ModelCheckPoint의 save_freq 를 숫자로 설정할 경우 사용.\n",
        "  num_examples_per_epoch = 2500 # 1 epochs 시 적용하는 examples 개수\n",
        "  num_epochs = 15 # epochs 횟수\n",
        "  train_file_pattern = '/content/tfrecord/train/pascal-*.tfrecord' # 학습용 tfrecords를 glob 형태로 가져오는 표현식.\n",
        "  val_file_pattern = '/content/tfrecord/val/pascal-*.tfrecord' # 검증용 tfrecords를 glob 형태로 가져오는 표현식.\n",
        "  val_json_file = None # optional coco validation json\n",
        "  mode = 'traineval' # train만 적용 또는 train과 eval함께 적용(traineval)\n",
        "\n",
        "  num_cores = 2 # tpu 8 일때 적용.\n",
        "  tpu = None\n",
        "  gcp_project = None\n",
        "  tpu_zone = None\n",
        "  eval_master = ''\n",
        "  eval_name = None\n",
        "  tf_random_seed = 2021\n",
        "  profile = False\n",
        "  debug = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ZVTurggZKm"
      },
      "source": [
        "# 강의영상에는 from keras import anchors 이지만 efficientdet 패키지의 keras 모듈이 tf2 로 변경됨.\n",
        "from tf2.train import setup_model\n",
        "import hparams_config\n",
        "\n",
        "import utils\n",
        "#from tf2 import tfmot\n",
        "from tf2 import train_lib\n",
        "from tf2 import util_keras\n",
        "\n",
        "config = hparams_config.get_detection_config(TRAIN_CFG.model_name)\n",
        "config.override(TRAIN_CFG.hparams)\n",
        "\n",
        "steps_per_epoch = TRAIN_CFG.num_examples_per_epoch // TRAIN_CFG.batch_size\n",
        "\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "  ds_strategy = tf.distribute.OneDeviceStrategy('device:GPU:0')\n",
        "else:\n",
        "  ds_strategy = tf.distribute.OneDeviceStrategy('device:CPU:0')\n",
        "\n",
        "print(ds_strategy)\n",
        "\n",
        "#steps_per_execution은 ModelCheckpoint의 save_freq를 숫자로 설정할 시 적용. num_epochs, steps_per_epoch는 추후에 model.fit()에서 설정되지만, 여기서는 일단 값을 설정해야함.\n",
        "params = dict(\n",
        "      profile=TRAIN_CFG.profile,\n",
        "      mode = TRAIN_CFG.mode,\n",
        "      model_name=TRAIN_CFG.model_name,\n",
        "      steps_per_execution=TRAIN_CFG.steps_per_execution,\n",
        "      num_epochs = TRAIN_CFG.num_epochs,\n",
        "      model_dir=TRAIN_CFG.model_dir,\n",
        "      steps_per_epoch=steps_per_epoch,\n",
        "      strategy=TRAIN_CFG.strategy,\n",
        "      batch_size=TRAIN_CFG.batch_size,\n",
        "      tf_random_seed=TRAIN_CFG.tf_random_seed,\n",
        "      debug=TRAIN_CFG.debug,\n",
        "      val_json_file=TRAIN_CFG.val_json_file,\n",
        "      eval_samples=TRAIN_CFG.eval_samples,\n",
        "      num_shards=ds_strategy.num_replicas_in_sync\n",
        "      )\n",
        "\n",
        "config.override(params, True)\n",
        "\n",
        "# image size를 tuple 형태로 변환. 512는 (512, 512)로 '1920x880' 은 (1920, 880) 으로 변환.\n",
        "config.image_size = utils.parse_image_size(config.image_size)\n",
        "print(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFlw575d0yG-"
      },
      "source": [
        "### Model 생성\n",
        "* Config를 기반으로 EfficientDet d0 모델을 생성\n",
        "* Coco Pretrained 파일을 다운로드 한 뒤 이 checkpoint파일의 weight를 생성한 d0 모델로 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Ghv3cZnRsG"
      },
      "source": [
        "import utils\n",
        "# 강의영상에는 from keras import anchors 이지만 efficientdet 패키지의 keras 모듈이 tf2 로 변경됨.\n",
        "#from tf2 import tfmot\n",
        "from tf2 import train_lib\n",
        "from tf2 import util_keras\n",
        "# P100 GPU Card에서는 아래 수행하지 말것. V100 GPU 시에는 mixed_float16으로 mixed_precision 설정.\n",
        "#precision = utils.get_precision(config.strategy, config.mixed_precision)\n",
        "#policy = tf.keras.mixed_precision.Policy(precision)\n",
        "#tf.keras.mixed_precision.set_global_policy(policy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzJmBbCu0-v5"
      },
      "source": [
        "MODEL = 'efficientdet-d0'\n",
        "\n",
        "def download(m):\n",
        "  if m not in os.listdir():\n",
        "    !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco/{m}.tar.gz\n",
        "    !tar zxf {m}.tar.gz\n",
        "  ckpt_path = os.path.join(os.getcwd(), m)\n",
        "  return ckpt_path\n",
        "\n",
        "# Download checkpoint.\n",
        "ckpt_path = download(MODEL)\n",
        "print('Use model in {}'.format(ckpt_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee5H613CnUy2"
      },
      "source": [
        "# 강의영상에는 from keras import anchors 이지만 efficientdet 패키지의 keras 모듈이 tf2 로 변경됨.\n",
        "from tf2 import train_lib\n",
        "from tf2 import train\n",
        "\n",
        "# 20개의 class를 가진 efficientdet d0 모델을 생성.\n",
        "model = train_lib.EfficientDetNetTrain(config=config)\n",
        "model = train.setup_model(model, config)\n",
        "\n",
        "# 만약 pretrained 모델이 있으면, 해당 checkpoint weight를 모델로 로딩. 이때 classification layer는 제외.\n",
        "#class TRAIN_CFG: pretrained_ckpt = '/content/efficientdet-d0'\n",
        "if TRAIN_CFG.pretrained_ckpt:\n",
        "  ckpt_path = tf.train.latest_checkpoint(TRAIN_CFG.pretrained_ckpt)\n",
        "  util_keras.restore_ckpt(\n",
        "      model,\n",
        "      ckpt_path,\n",
        "      config.moving_average_decay,\n",
        "      exclude_layers=['class_net'])\n",
        "\n",
        "train.init_experimental(config)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMn6nBYQ1HHr"
      },
      "source": [
        "### 학습과 검증용 Dataset을 생성하고, Train 수행.\n",
        "* 학습과 검증 데이터용 dataset 생성을 위한 get_dataset() 함수 생성."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daTGBW0CtowG"
      },
      "source": [
        "'''\n",
        "Class TRAIN_CFG:\n",
        "  train_file_pattern = '/content/tfrecord/train/pascal-*.tfrecord' # 학습용 tfrecords를 glob 형태로 가져오는 표현식.\n",
        "  val_file_pattern = '/content/tfrecord/val/pascal-*.tfrecord' # 검증용 tfrecords를 glob 형태로 가져오는 표현식.\n",
        "'''\n",
        "\n",
        "import dataloader\n",
        "\n",
        "def get_dataset(is_training, config):\n",
        "  # is_training이 True이면 TRAIN_CFG의 train_file_pattern, 그렇지 아니면 val_file_pattern\n",
        "  file_pattern = (\n",
        "    TRAIN_CFG.train_file_pattern\n",
        "    if is_training else TRAIN_CFG.val_file_pattern)\n",
        "  if not file_pattern:\n",
        "    raise ValueError('No matching files.')\n",
        "\n",
        "  return dataloader.InputReader(\n",
        "    file_pattern,\n",
        "    is_training=is_training,\n",
        "    use_fake_data=TRAIN_CFG.use_fake_data,\n",
        "    max_instances_per_image=config.max_instances_per_image,\n",
        "    debug=TRAIN_CFG.debug)(\n",
        "        config.as_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pks9JJTk5qm4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#  train.txt와 val.txt를 읽어서 train과 val 용 image 건수를 구함\n",
        "train_df = pd.read_csv('/content/VOCdevkit/VOC2007/ImageSets/Main/train.txt', sep=' ',\n",
        "                       header=None, names=['file_id'], dtype={'file_id':str})\n",
        "val_df = pd.read_csv('/content/VOCdevkit/VOC2007/ImageSets/Main/val.txt', sep=' ',\n",
        "                       header=None, names=['file_id'], dtype={'file_id':str})\n",
        "\n",
        "train_images_num = train_df.shape[0]\n",
        "val_images_num = val_df.shape[0]\n",
        "print(train_images_num, val_images_num)\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMBcEL3iVvL0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tf2 import train_lib\n",
        "from tf2 import train\n",
        "\n",
        "# config에 기반하여 모델을 생성하고 pretrained weight를 로딩하는 함수 생성.\n",
        "def get_efficientdet_model(config):\n",
        "  model = train_lib.EfficientDetNetTrain(config=config)\n",
        "  model = train.setup_model(model, config)\n",
        "\n",
        "  if TRAIN_CFG.pretrained_ckpt:\n",
        "    ckpt_path = tf.train.latest_checkpoint(TRAIN_CFG.pretrained_ckpt)\n",
        "    util_keras.restore_ckpt(\n",
        "        model,\n",
        "        ckpt_path,\n",
        "        config.moving_average_decay,\n",
        "        exclude_layers=['class_net'])\n",
        "\n",
        "  train.init_experimental(config)\n",
        "  return model\n",
        "\n",
        "model = get_efficientdet_model(config)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YeD9OD1slQF"
      },
      "source": [
        "from tf2 import train\n",
        "import numpy as np\n",
        "\n",
        "# config에 설정된 steps_per_epoch, num_epochs는 무시하고 여기서 새로 설정.\n",
        "# steps_per_epoch는 전체 학습데이터 이미지 건수//batch_size, val_steps_per_epoch는 전체 검증 데이터 이미지 건수//batch_size\n",
        "tr_steps_per_epoch = train_images_num//config.batch_size\n",
        "val_steps_per_epoch = val_images_num//config.batch_size\n",
        "print('tr_steps_per_epoch:', tr_steps_per_epoch, 'val_steps_per_epoch:', val_steps_per_epoch)\n",
        "\n",
        "#  config.mode가 traineval 또는 eval일 경우 검증 dataset 생성.\n",
        "val_dataset = get_dataset(False, config) if 'eval' in config.mode else None\n",
        "#callback은 config에 설정된 구성대로 생성. ModelCheckpoint는 epoch시마다, COCO Evaluation는 5회 epoch시마다 수행됨.\n",
        "#config.save_freq = eval;config.map_freq = 5\n",
        "# 1 epoch시마다 P100에서 약 3분30초 걸림. 적절한 epochs 수 설정 필요.\n",
        "model.fit(\n",
        "    get_dataset(True, config),\n",
        "    epochs=15,\n",
        "    steps_per_epoch=tr_steps_per_epoch ,\n",
        "    callbacks=train_lib.get_callbacks(config.as_dict(), val_dataset),\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=val_steps_per_epoch)\n",
        "\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxOF8I65bsoC"
      },
      "source": [
        "### 학습된 모델 파일을 이용하여 Inference 수행."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUytyj8iB5lP"
      },
      "source": [
        "import hparams_config\n",
        "\n",
        "infer_config = hparams_config.get_efficientdet_config('efficientdet-d0')\n",
        "print(infer_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiBgbQE3HgpH"
      },
      "source": [
        "\n",
        "infer_config = hparams_config.get_efficientdet_config('efficientdet-d0')\n",
        "# config의 특정 항목을 update\n",
        "infer_config.model_name = 'efficientdet-d0'\n",
        "infer_config.model_dir = '/mydrive/model_trained'\n",
        "# infer_config의 num_classes는 20로 바뀌어야 함.\n",
        "infer_config.num_classes =20\n",
        "infer_config.is_training_bn = False\n",
        "infer_config.nms_configs.score_thresh = 0.4\n",
        "infer_config.nms_configs.max_output_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdTAZz-mx2kk"
      },
      "source": [
        "import inference\n",
        "from tf2 import efficientdet_keras\n",
        "\n",
        "model = efficientdet_keras.EfficientDetModel(config=infer_config)\n",
        "model.build((None, None, None, 3))\n",
        "print('#### checkpoint name:', tf.train.latest_checkpoint(infer_config.model_dir))\n",
        "model.load_weights(tf.train.latest_checkpoint(infer_config.model_dir))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li-k5zj51s-l"
      },
      "source": [
        "import time\n",
        "\n",
        "class ExportModel(tf.Module):\n",
        "\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function\n",
        "  def f(self, imgs):\n",
        "    #model(imgs, training=False, post_mode='global')\n",
        "    return self.model(imgs, training=False, post_mode='global')\n",
        "\n",
        "export_model = ExportModel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jp_ySCe1tBh"
      },
      "source": [
        "!mkdir -p /content/data\n",
        "!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg\n",
        "!wget -O ./data/baseball01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/baseball01.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFJUeV031wHy"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.cvtColor(cv2.imread('/content/data/beatles01.jpg'), cv2.COLOR_BGR2RGB)\n",
        "imgs= img[np.newaxis, ...]\n",
        "\n",
        "start_time = time.time()\n",
        "boxes, scores, classes, valid_len = export_model.f(imgs)\n",
        "\n",
        "print('elapsed time:', time.time() - start_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdaDV_NN1wKy"
      },
      "source": [
        "labels_to_names =  {1:'aeroplane', 2:'bicycle', 3:'bird', 4:'boat', 5:'bottle', 6:'bus', 7:'car',\n",
        "               8:'cat', 9:'chair', 10:'cow', 11:'diningtable', 12:'dog', 13:'horse',\n",
        "               14:'motorbike', 15:'person', 16:'pottedplant', 17:'sheep', 18:'sofa', 19:'train',\n",
        "               20:'tvmonitor'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGhu-oo214y7"
      },
      "source": [
        "def get_detected_img(export_model, img_array, is_print=True):\n",
        "  # automl efficent은 반환 bbox 좌표값이 원본 이미지 좌표값으로 되어 있으므로 별도의 scaling작업 필요 없음.\n",
        "  '''\n",
        "  height = img_array.shape[0]\n",
        "  width = img_array.shape[1]\n",
        "  '''\n",
        "  # cv2의 rectangle()은 인자로 들어온 이미지 배열에 직접 사각형을 업데이트 하므로 그림 표현을 위한 별도의 이미지 배열 생성.\n",
        "  draw_img = img_array.copy()\n",
        "\n",
        "  # bounding box의 테두리와 caption 글자색 지정\n",
        "  green_color=(0, 255, 0)\n",
        "  red_color=(0, 0, 255)\n",
        "\n",
        "  # cv2로 만들어진 numpy image array를 tensor로 변환\n",
        "  img_tensor = tf.convert_to_tensor(img_array, dtype=tf.uint8)[tf.newaxis, ...]\n",
        "  #img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)[tf.newaxis, ...]\n",
        "\n",
        "  # efficientdet 모델을 다운로드 한 뒤 inference 수행.\n",
        "  start_time = time.time()\n",
        "  # automl efficientdet 모델은 boxes, score, classes, num_detections를 각각 Tensor로 반환.\n",
        "  boxes, scores, classes, valid_len = export_model.f(img_tensor)\n",
        "  # Tensor값을 시각화를 위해 numpy 로 변환.\n",
        "  boxes = boxes.numpy()\n",
        "  scores = scores.numpy()\n",
        "  classes = classes.numpy()\n",
        "  valid_len = valid_len.numpy()\n",
        "\n",
        "  # detected 된 object들을 iteration 하면서 정보 추출. detect된 object의 갯수는 100개\n",
        "  for i in range(valid_len[0]):\n",
        "    # detection score를 iteration시 마다 높은 순으로 추출하고 SCORE_THRESHOLD보다 낮으면 loop 중단.\n",
        "    score = scores[0, i]\n",
        "\n",
        "    # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n",
        "    box = boxes[0, i]\n",
        "\n",
        "    ''' **** 주의 ******\n",
        "    box는 ymin, xmin, ymax, xmax 순서로 되어 있음. 또한 원본 좌표값으로 되어 있음. '''\n",
        "    left = box[1]\n",
        "    top = box[0]\n",
        "    right = box[3]\n",
        "    bottom = box[2]\n",
        "\n",
        "    # class id 추출하고 class 명으로 매핑\n",
        "    class_id = classes[0, i]\n",
        "    caption = \"{}: {:.4f}\".format(labels_to_names[class_id], score)\n",
        "    print(caption)\n",
        "    #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n",
        "    cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n",
        "    cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, red_color, 1)\n",
        "\n",
        "  if is_print:\n",
        "    print('Detection 수행시간:',round(time.time() - start_time, 2),\"초\")\n",
        "\n",
        "  return draw_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6_6o7Ux19df"
      },
      "source": [
        "import cv2\n",
        "img_array = cv2.cvtColor(cv2.imread('/content/data/beatles01.jpg'), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "draw_img = get_detected_img(export_model, img_array, is_print=True)\n",
        "plt.figure(figsize=(16, 16))\n",
        "plt.imshow(draw_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6XUy5Vg1_Ks"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}